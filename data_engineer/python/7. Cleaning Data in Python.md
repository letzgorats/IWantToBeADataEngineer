## ğŸ§¹ Pythonìœ¼ë¡œ ë°°ìš°ëŠ” ë°ì´í„° í´ë¦¬ë‹ â€“ Common Data Problems ì™„ë²½ ê°€ì´ë“œ
ë°ì´í„° ë¶„ì„ì´ë‚˜ ë¨¸ì‹ ëŸ¬ë‹ í”„ë¡œì íŠ¸ì—ì„œ **ë°ì´í„° í´ë¦¬ë‹(data cleaning)** ì€ í•„ìˆ˜ ê³¼ì •ì…ë‹ˆë‹¤.
ì•„ë¬´ë¦¬ ë›°ì–´ë‚œ ëª¨ë¸ê³¼ ì‹œê°í™” ê¸°ë²•ì„ ì‚¬ìš©í•˜ë”ë¼ë„, ì…ë ¥ ë°ì´í„°ê°€ ì—‰ë§ì´ë¼ë©´ ê²°ê³¼ ì—­ì‹œ ë¯¿ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
ì´ ê¸€ì—ì„œëŠ” Pythonê³¼ Pandasë¥¼ í™œìš©í•´ ê°€ì¥ í”í•˜ê²Œ ë°œìƒí•˜ëŠ” ë°ì´í„° ë¬¸ì œì™€ í•´ê²° ë°©ë²•ì„ ì •ë¦¬í•©ë‹ˆë‹¤.

### 1. ë°ì´í„° íƒ€ì… ì œì•½ (Data Type Constraints)
#### ì™œ ì¤‘ìš”í•œê°€?
ë°ì´í„° íƒ€ì…ì´ ì˜ëª» ì§€ì •ë˜ì–´ ìˆìœ¼ë©´ ì—°ì‚°ì´ ì—‰ëš±í•˜ê²Œ ë™ì‘í•˜ê±°ë‚˜, ë¶„ì„ ê³¼ì •ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ì˜ˆë¥¼ ë“¤ì–´ ìˆ«ìì²˜ëŸ¼ ë³´ì´ì§€ë§Œ ë¬¸ìì—´ë¡œ ì €ì¥ëœ ë°ì´í„°ëŠ” í•©ì‚° ì—°ì‚° ì‹œ ìˆ«ìê°€ ì•„ë‹Œ ë¬¸ìì—´ì´ ì´ì–´ë¶™ì—¬ì§‘ë‹ˆë‹¤.

#### ì£¼ìš” ì˜ˆì‹œ

```python
import pandas as pd

# ì˜ëª»ëœ ë°ì´í„° íƒ€ì… ì˜ˆì‹œ
df = pd.DataFrame({
    "Revenue": ["$1000", "$2500", "$4000"]
})

print(df.dtypes)
# Revenue    object
```
> Revenue ì»¬ëŸ¼ì´ object(ë¬¸ìì—´)ë¡œ ì €ì¥ë˜ì–´ ìˆì–´ í•©ì‚° ë¶ˆê°€ â†’ $ ê¸°í˜¸ ì œê±° í›„ ìˆ«ìë¡œ ë³€í™˜ í•„ìš”.

#### í•´ê²°ë°©ë²•
```python
# 1) $ ì œê±°
df["Revenue"] = df["Revenue"].str.strip('$')

# 2) ì •ìˆ˜í˜• ë³€í™˜
df["Revenue"] = df["Revenue"].astype(int)

# 3) ê²€ì¦
assert df["Revenue"].dtype == "int"
```

#### ğŸ’¡ Tip:

> ê¸ˆì•¡ì— ì†Œìˆ˜ì ì´ ìˆë‹¤ë©´ floatë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

> ë²”ì£¼í˜• ì½”ë“œ(ì˜ˆ: ê²°í˜¼ ì—¬ë¶€ 0/1/2/3)ëŠ” category íƒ€ì…ìœ¼ë¡œ ë³€í™˜í•˜ë©´ ë¶ˆí•„ìš”í•œ í†µê³„ ê³„ì‚°ì„ ë°©ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


### 1-1. íƒ€ì… ì§„ë‹¨ : `dtypes`, `info()`
```python
df.dtypes # ê° ì»¬ëŸ¼ dtype
df.info() # dtype -> ê²°ì¸¡ì¹˜ ê°œìš” í™•ì¸
```
> ë¬¸ìì—´ ìˆ«ì, ë‚ ì§œê°€ ë¬¸ìì—´(object)ë¡œ ë“¤ì–´ì˜¤ëŠ” ê²½ìš°ê°€ ê°€ì¥ í”í•©ë‹ˆë‹¤.

### 1-2. ë¬¸ìì—´ ê¸ˆì•¡/ìˆ«ì â†’ ìˆ«ìí˜• ë³€í™˜
í˜„ì‹¤ ë°ì´í„°ëŠ” `$`, `,`, `ê³µë°±`, `ìŒìˆ˜ ê´„í˜¸(1,234)` ê°™ì€ **â€œì¡ìŒ ë¬¸ìâ€** ê°€ ë§ìŠµë‹ˆë‹¤.
```python
import pandas as pd

df = pd.DataFrame({
    "revenue": ["$1,000", "2,500", " -300", "(450) ", "abc"]  # ë‹¤ì–‘í•˜ê²Œ ì„ì—¬ ìˆìŒ
})

# 1) ìˆ«ì/ë¶€í˜¸/ì†Œìˆ˜ì /í•˜ì´í”ˆë§Œ ë‚¨ê¸°ê³  ëª¨ë‘ ì œê±°
df["revenue_clean"] = (
    df["revenue"].str.strip()
                   .str.replace(r"[^\d\-\.\(\)]", "", regex=True)  # ê¸°í˜¸ ì™¸ ì œê±°
                   .str.replace(r"^\((.*)\)$", r"-\1", regex=True) # (450) â†’ -450
)

# 2) ì•ˆì „ ë³€í™˜: ì˜ëª»ëœ ê°’ì€ NaNìœ¼ë¡œ
df["revenue_num"] = pd.to_numeric(df["revenue_clean"], errors="coerce")

# 3) ê²€ì¦
assert df["revenue_num"].dtype.kind in ("i", "f")  # ì •ìˆ˜(i) ë˜ëŠ” ì‹¤ìˆ˜(f)
```
#### ì‹¤ë¬´íŒ
> - "ë³€í™˜ ì‹¤íŒ¨ë¥¼ ê°•ì œë¡œ ì—ëŸ¬ ë‚´ê³  ì‹¶ë‹¤ë©´ `errors="raise"` ë¥¼ ì‚¬ìš©í•´ ì¡°ê¸°ì— ë°ì´í„° ë¬¸ì œë¥¼ ë“œëŸ¬ë‚´ì„¸ìš”."

> - "í†µí™” ë‹¨ìœ„ê°€ í˜¼ì¬(USD/JPY ë“±)í•˜ë©´ ë‹¨ìœ„ í‘œì¤€í™”ë¥¼ ë¨¼ì € í•˜ì„¸ìš”!"

### 1-3. ë²”ì£¼í˜• ì½”ë“œ â†’ ë²”ì£¼í˜•(category)
ìˆ«ìì²˜ëŸ¼ ë³´ì´ì§€ë§Œ â€œì½”ë“œâ€ì¸ ê²½ìš°(ì˜ˆ: ê²°í˜¼ìƒíƒœ 0/1/2/3)ëŠ” ë²”ì£¼í˜•ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
```python
from pandas.api.types import CategoricalDtype

marital_order = CategoricalDtype(categories=[0,1,2,3], ordered=True)
df["marital_status"] = df["marital_status"].astype(marital_order)

# ìš”ì•½ í†µê³„ê°€ í‰ê· /í‘œì¤€í¸ì°¨ ëŒ€ì‹ , unique/ìµœë¹ˆê°’ ìœ„ì£¼ë¡œ ë°”ë€œ
df["marital_status"].describe()
```

#### ì‹¤ë¬´ íŒ
> - **"ë¼ë²¨ ë§¤í•‘** ê¹Œì§€ í•´ë‘ë©´ ê°€ë…ì„±ê³¼ EDA íš¨ìœ¨ì´ ì˜¬ë¼ê°‘ë‹ˆë‹¤."
```python
label = {0:"Never", 1:"Married", 2:"Separated", 3:"Divorced"}
df["marital_label"] = df["marital_status"].map(label)
```

### 1-4. ë¬¸ìì—´ ë‚ ì§œ â†’ `datetime64[ns]`
```python
import pandas as pd

df = pd.DataFrame({"subscription_date": ["2025/07/28", "07-29-2025", "2025.08.40", None]})

# ê°€ì¥ ì•ˆì „í•œ ë°©ì‹: to_datetime 1ë‹¨ê³„ ë³€í™˜ í›„ ë²¡í„° ì—°ì‚° í™œìš©
df["subscription_dt"] = pd.to_datetime(
    df["subscription_date"],
    errors="coerce",        # ì˜ëª»ëœ ë‚ ì§œëŠ” NaT
    infer_datetime_format=True, # ëŒ€ì²´ë¡œ OK (ë²„ì „ì— ë”°ë¼ ë¬´ì‹œë˜ê¸°ë„ í•¨)
)

# í˜•ì‹ì´ ì¼ì •í•˜ë‹¤ë©´ format ì§€ì •ì´ ê°€ì¥ í™•ì‹¤
df["subscription_dt"] = pd.to_datetime(df["subscription_date"], format="%Y/%m/%d", errors="coerce")
```
> ì£¼ì˜

> - "`errors="coerce"` ëŠ” í’ˆì§ˆ ê²½ê³ ë“±ì…ë‹ˆë‹¤. (ë¶„ì„ ì „, ë°˜ë“œì‹œ ê²°ì¸¡/NaT ì²˜ë¦¬ ê¸°ì¤€ì„ ìˆ˜ë¦½í•´ì•¼ í•©ë‹ˆë‹¤.)"
> - "`dayfirst=True`(EU í˜•ì‹) / `yearfirst=True` ë¡œ ì§€ì—­ í˜•ì‹ í˜¼ì„  í•´ì†Œí•©ë‹ˆë‹¤." 

### 1-5. íƒ€ì„ì¡´ ì²˜ë¦¬(ìˆë‹¤ë©´)
- naive(íƒ€ì„ì¡´ ì—†ìŒ) â†’ `tz_localize`
- aware(íƒ€ì„ì¡´ ìˆìŒ) â†’ `tz_convert`

```python
# naive timestampë¥¼ 'Asia/Seoul' ê¸°ì¤€ìœ¼ë¡œ í•´ì„
df["ts_kr"] = pd.to_datetime(df["subscription_date"], errors="coerce").dt.tz_localize("Asia/Seoul")

# ì´ë¯¸ tz-awareì´ë©´ ì‹œê°„ëŒ€ ë³€í™˜ë§Œ
df["ts_utc"] = df["ts_kr"].dt.tz_convert("UTC")
```
> ì‹¤ë¬´ íŒ

> - "ì €ì¥ì´ ì–¸ì œ/ì–´ë”” ì‹œê°„ëŒ€ì¸ì§€" ëª…ì„¸ë¥¼ ê³ ì •í•˜ëŠ”ê²Œ ì¢‹ìŠµë‹ˆë‹¤. ë³´í†µ ì›ì²œ ìˆ˜ì§‘ ì‹œ UTCë¡œ ê³ ì • ì €ì¥ë˜ëŠ”ë°, í‘œì‹œ ë‹¨ê³„ì—ì„œ í•„ìš”ì— ë”°ë¼ ì§€ì—­ ì‹œê°„ëŒ€ë¡œ ë³€í™˜í•˜ë©´ ì¢‹ìŠµë‹ˆë‹¤.

### 2. ë°ì´í„° ë²”ìœ„ ì œì•½ (Data Range Constraints)

#### ë¬¸ì œ ìƒí™©
ë°ì´í„° ê°’ì´ í—ˆìš© ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ëŠ” ê²½ìš°ì…ë‹ˆë‹¤.
- ì˜ˆ: ì˜í™” í‰ì (1~5)ì¸ë°, 6ì ì´ ì¡´ì¬
- ì˜ˆ: ê°€ì…ì¼ì´ í˜„ì¬ ë‚ ì§œë³´ë‹¤ ë¯¸ë˜

#### ë²”ìœ„ ê²€ì¦ & ì²˜ë¦¬
```python
# ì˜ˆ: ì˜í™” í‰ì 
movies = pd.DataFrame({"avg_rating": [4, 5, 6, 3]})

# 5ì ì„ ì´ˆê³¼í•˜ëŠ” ê°’ ì°¾ê¸°
invalid_rows = movies[movies["avg_rating"] > 5]

# ë°©ë²• 1: ì‚­ì œ
movies = movies[movies["avg_rating"] <= 5]

# ë°©ë²• 2: ìµœëŒ€ê°’ìœ¼ë¡œ ë³€ê²½
movies.loc[movies["avg_rating"] > 5, "avg_rating"] = 5
```

#### ğŸ’¡ Tip:

> ì‚­ì œëŠ” ë°ì´í„° ì†ì‹¤ì„ ìœ ë°œí•˜ë¯€ë¡œ ë¹„ìœ¨ì´ ì ì„ ë•Œë§Œ ì‚¬ìš©.

> ë‚ ì§œ ì²˜ë¦¬ ì‹œ `pd.to_datetime()`ìœ¼ë¡œ ë³€í™˜ í›„ ë¹„êµ:

```python
from datetime import date
df["subscription_date"] = pd.to_datetime(df["subscription_date"]).dt.date
today = date.today()
df = df[df["subscription_date"] <= today]
```

### 2-1. "ë¯¸ë˜ ë‚ ì§œ" í•„í„°ë§/ë³´ì •
ë¶„ì„ ê¸°ì¤€ì¼(ì˜¤ëŠ˜)ê³¼ ë¹„êµí•˜ë ¤ë©´ **ì‹œì  í†µì¼**ì´ ì¤‘ìš”í•©ë‹ˆë‹¤.
```python
from datetime import date
import pandas as pd

# 1) Datetime ë³´ì¡´(ê¶Œì¥): normalize()ë¡œ ì‹œê° ì œê±°(ìì • ê¸°ì¤€)
today_ts = pd.Timestamp.today().normalize()      # ì˜¤ëŠ˜ 00:00:00 (ë¡œì»¬)
mask_future = df["subscription_dt"] > today_ts
future_rows = df[mask_future]

# 2) ë°”ë¡œ ì‚­ì œ
df_drop = df.loc[~mask_future].copy()

# 3) í•˜ë“œ ë¦¬ë°‹(ë¯¸ë˜ â†’ ì˜¤ëŠ˜ë¡œ ìº¡í•‘)
df_cap = df.copy()
df_cap.loc[mask_future, "subscription_dt"] = today_ts

# 4) ê²€ì¦
assert (df_drop["subscription_dt"] <= today_ts).all()
assert (df_cap["subscription_dt"] <= today_ts).all()

```
> ì™œ `dt.date` ëŒ€ì‹  `datetime` ìœ ì§€ê°€ ì¢‹ì€ê°€?

> - `datetime64[ns]` ëŠ” ë²¡í„° ì—°ì‚°/ë¦¬ìƒ˜í”Œë§/ë¡¤ë§ ìœˆë„ìš° ë“± ì‹œê°„ ì—°ì‚° ìµœì í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

> - ê¼­ **ë‚ ì§œë§Œ í•„ìš”í•  ë•Œë§Œ** `df["subscription_dt"].dt.date` ë¡œ íŒŒìƒ ì»¬ëŸ¼ì„ ë§Œë“œëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.

### 2-2. ë²”ìœ„ ì œì•½ : í—ˆìš© êµ¬ê°„ ë°– ê°’ ë‹¤ë£¨ê¸°(ì‚­ì œ/ìº¡í•‘/ê²°ì¸¡í™”)
ì˜í™” í‰ì (1~5) ì˜ˆì‹œë¡œ 3ê°€ì§€ ì „í˜•ì  ì²˜ë¦¬ë²•ì„ ë¹„êµí•´ë´…ì‹œë‹¤.
```python
movies = pd.DataFrame({"avg_rating": [1,3,5,6,0,4,7]})

# (A) ì‚­ì œ (outlier proportionì´ ë§¤ìš° ë‚®ì„ ë•Œ)
mov_a = movies.loc[movies["avg_rating"].between(1,5)].copy()

# (B) ìº¡í•‘ (winsorize; ë¹„ì¦ˆë‹ˆìŠ¤ ë£°ë¡œ ìƒí•œ/í•˜í•œ ê³ ì •)
mov_b = movies.copy()
mov_b.loc[mov_b["avg_rating"] < 1, "avg_rating"] = 1
mov_b.loc[mov_b["avg_rating"] > 5, "avg_rating"] = 5

# (C) ê²°ì¸¡í™” í›„ ì ì ˆí•œ Impute(ë‹¤ìŒ ì¥ì—ì„œ ë‹¤ë£¸)
mov_c = movies.copy()
mask = ~movies["avg_rating"].between(1,5)
mov_c.loc[mask, "avg_rating"] = pd.NA

# ê²€ì¦
assert mov_a["avg_rating"].between(1,5).all()
assert mov_b["avg_rating"].between(1,5).all()
```

> ì˜ì‚¬ê²°ì • ê°€ì´ë“œ

> - í‘œë³¸ì´ ì‘ìœ¼ë©´ ì‚­ì œëŠ” ìœ„í—˜í•©ë‹ˆë‹¤.
> - "í‰ì  ì‹œìŠ¤í…œì´ 1~5ë¡œ ì„¤ê³„" ì²˜ëŸ¼ í•˜ë“œ ë£°ì´ ëª…í™•í•˜ë©´ ìº¡í•‘ì´ ì‹¤ìš©ì ì…ë‹ˆë‹¤.
> - ë°ì´í„° ìƒì„± ê³¼ì •ì´ ë¶ˆí™•ì‹¤í•˜ê±°ë‚˜ ë¹„ì¦ˆë‹ˆìŠ¤ ë£°ì´ ëª¨í˜¸í•˜ë‹¤ë©´, ê²°ì¸¡ ì²˜ë¦¬ í›„ ì ì ˆí•œ ëŒ€ì¹˜ê°€ ì•ˆì „í•©ë‹ˆë‹¤.

### 3. ìœ ë‹ˆí¬ ì œì•½ (Uniqueness Constraints)

#### ë¬¸ì œ ìƒí™©
ì¤‘ë³µ ë°ì´í„°ê°€ ì¡´ì¬í•˜ë©´ ë¶„ì„ì´ ì™œê³¡ë©ë‹ˆë‹¤.
- **ì™„ì „ ì¤‘ë³µ** : ëª¨ë“  ì»¬ëŸ¼ ê°’ì´ ë™ì¼í•œ í–‰ì´ ë°˜ë³µ (ëª¨ë“  ì»¬ëŸ¼ ë™ì¼)
- **ë¶€ë¶„ ì¤‘ë³µ** : íŠ¹ì • í‚¤ ì»¬ëŸ¼ì€ ê°™ì§€ë§Œ, ë‚˜ë¨¸ì§€ ê°’ì´ ë‹¤ë¦„ (ì¼ë¶€ ì»¬ëŸ¼ë§Œ ë™ì¼, ë‹¤ë¥¸ ê°’ì´ ì¡´ì¬) - (ê°±ì‹ /ì˜¤íƒ€/ì„¼ì„œ ë³€ë™ ë“±)

#### ì¤‘ë³µ ì°¾ê¸°
```python
# ì™„ì „ ì¤‘ë³µ ì—¬ë¶€
df.duplicated()

# íŠ¹ì • ì»¬ëŸ¼ ê¸°ì¤€
df.duplicated(subset=["first_name", "last_name"], keep=False)
```

#### ì²˜ë¦¬ ë°©ë²•
**1) ì™„ì „ ì¤‘ë³µ ì œê±°**
```python
df = df.drop_duplicates()
```

**2) ë¶€ë¶„ ì¤‘ë³µ ì²˜ë¦¬ (í†µê³„ ê¸°ë°˜ ë³‘í•©)**
```python
summaries = {"height": "max", "weight": "mean"}
df = df.groupby(["first_name", "last_name", "address"]).agg(summaries).reset_index()
```

#### ğŸ’¡ Tip:

> ì¤‘ë³µ ì²˜ë¦¬ë¥¼ ë¬´ì¡°ê±´ ì‚­ì œë¡œ í•˜ì§€ ë§ê³ , ë„ë©”ì¸ ì§€ì‹ì— ë”°ë¼ í‰ê· Â·ìµœëŒ€Â·ìµœì†Œ ë“±ìœ¼ë¡œ ë³‘í•©.

> ì¤‘ë³µ ì—¬ë¶€ í™•ì¸ í›„ `assert df.duplicated().sum() == 0` ë¡œ ê²€ì¦ ê°€ëŠ¥.


### 3-1. `duplicated()`ì˜ í•µì‹¬ ì¸ì - `subset`, `keep` ì™„ì „ ì´í•´
- `subset` : ì¤‘ë³µ íŒë‹¨ì— ì“¸ ì»¬ëŸ¼ ì§‘í•© (ê¸°ë³¸ê°’:`None` â†’ ëª¨ë“  ì»¬ëŸ¼ ë¹„êµ)
- `keep` : ì–´ëŠ ì¤‘ë³µì„ **ì›ë³¸(ê³ ìœ )**ìœ¼ë¡œ ë³´ê³  ë‚˜ë¨¸ì§€ë¥¼ `True`ë¡œ í•  í‘œì‹œí• ì§€ ê²°ì •** (**keep ë™ì‘ì—ì„œ â€œë‚¨ëŠ” ê±´ False, ì¤‘ë³µìœ¼ë¡œ íŒë‹¨ë˜ëŠ” ê±´ Trueâ€ ë¼ëŠ” ì ì„ ìˆ™ì§€í•˜ì„¸ìš”!**)
    - `first`(default) : **ì²« ë²ˆì§¸**ë¥¼ ê³ ìœ ë¡œ ë‚¨ê¸°ê³  ì´í›„ë¥¼ ì¤‘ë³µìœ¼ë¡œ í‘œì‹œ
    - `last` : **ë§ˆì§€ë§‰**ì„ ê³ ìœ ë¡œ ë‚¨ê¸°ê³  ì´ì „ì„ ì¤‘ë³µìœ¼ë¡œ í‘œì‹œ
    - `False` : **ëª¨ë“ ** ì¤‘ë³µ ë°œìƒ í–‰ì„ `True` ë¡œ í‘œì‹œ (ì¦‰, ê³ ìœ ë¡œ ë‚¨ê¸°ì§€ ì•ŠìŒ)
    

ì˜ˆì œ : ë™ëª…ì´ì¸ + ì£¼ì†Œ ë™ì¼ ì‹œ ê°™ì€ ì‚¬ëŒìœ¼ë¡œ íŒë‹¨
```python
people = pd.DataFrame({
    "first_name": ["Ann","Ann","Bob","Bob","Bob"],
    "last_name":  ["Kim","Kim","Lee","Lee","Lee"],
    "address":    ["Seoul","Seoul","Busan","Busan","Busan"],
    "height":     [160,160,175,176,175],
    "weight":     [55,55,70,72,71],
    "updated_at": ["2025-08-01","2025-08-01","2025-07-30","2025-08-01","2025-07-20"]
})

# 1) ì™„ì „ ì¤‘ë³µ íƒì§€(ëª¨ë“  ì»¬ëŸ¼ ë™ì¼í•´ì•¼ ì¤‘ë³µ)
dup_full = people.duplicated(keep=False)

# 2) í‚¤ ê¸°ì¤€ ë¶€ë¶„ ì¤‘ë³µ íƒì§€(ì´ë¦„+ì£¼ì†Œë§Œ ê¸°ì¤€)
key = ["first_name","last_name","address"]
dup_key_first = people.duplicated(subset=key, keep="first")
dup_key_last  = people.duplicated(subset=key, keep="last")
dup_key_all   = people.duplicated(subset=key, keep=False)

```
> `dup_key_first == True` : **ì²« ë“±ì¥ ì´í›„**ì˜ ë™ì¼ í‚¤ í–‰ë“¤

> `dup_key_last == True` : **ë§ˆì§€ë§‰ ì´ì „**ì˜ ë™ì¼ í‚¤ í–‰ë“¤

> `dup_key_all == True` : **ë™ì¼ í‚¤ì˜ ëª¨ë“  í–‰** (ì²«/ë§ˆì§€ë§‰ í¬í•¨)

#### ë°ì´í„° ì›ë³¸
| idx | first\_name | last\_name | address | height | weight | updated\_at |
| --- | ----------- | ---------- | ------- | ------ | ------ | ----------- |
| 0   | Ann         | Kim        | Seoul   | 160    | 55     | 2025-08-01  |
| 1   | Ann         | Kim        | Seoul   | 160    | 55     | 2025-08-01  |
| 2   | Bob         | Lee        | Busan   | 175    | 70     | 2025-07-30  |
| 3   | Bob         | Lee        | Busan   | 176    | 72     | 2025-08-01  |
| 4   | Bob         | Lee        | Busan   | 175    | 71     | 2025-07-20  |

#### 1) `dup_full = people.duplicated(keep=False)` 
- ëª¨ë“  ì»¬ëŸ¼ì´ ë™ì¼í•´ì•¼ True
- `(0)` ê³¼ `(1)`ì€ ì™„ì „ ë™ì¼  â†’ ë‘ í–‰ ëª¨ë‘ True
- `(2)`,`(3)`,`(4)`ëŠ” height/weightê°€ ë‹¬ë¼ì„œ ì™„ì „ ë™ì¼ ì•„ë‹˜ â†’ False
- âœ… ê²°ê³¼
  ```python
  [ True, True, False, False, False ]
  ```

#### 2) `dup_key_first = people.duplicated(subset=key, keep="first")` : ìœ„ì—ì„œ ì•„ë˜ë¡œ
- key = ["first_name","last_name","address"]
- ì²« ë²ˆì§¸ ë“±ì¥ í–‰ì€ False, ì´í›„ ê°™ì€ í‚¤ëŠ” True.
- Ann Kim Seoul â†’ idx 0ì€ False, idx 1ì€ True
- Bob Lee Busan â†’ idx 2ëŠ” False, idx 3 True, idx 4 True
- âœ… ê²°ê³¼
  ```python
  [ False, True, False, True, True ]
  ```
  
#### 3) `dup_key_last = people.duplicated(subset=key, keep="last")` : ì•„ë˜ì—ì„œ ìœ„ë¡œ
- ë§ˆì§€ë§‰ ë“±ì¥ í–‰ë§Œ False, ê·¸ ì´ì „ ë™ì¼ í‚¤ëŠ” True.
- Ann Kim Seoul â†’ idx 0 True, idx 1 False
- Bob Lee Busan â†’ idx 2 True, idx 3 True, idx 4 False
- âœ… ê²°ê³¼
  ```python
  [ True, False, True, True, False ]
  ```
  
#### 4) `dup_key_all = people.duplicated(subset=key, keep=False)`
- ë™ì¼ í‚¤ì˜ ëª¨ë“  í–‰ì´ True (ì²«/ë§ˆì§€ë§‰ êµ¬ë¶„ ì—†ìŒ).
- Ann Kim Seoul â†’ idx 0,1 ëª¨ë‘ True
- Bob Lee Busan â†’ idx 2,3,4 ëª¨ë‘ True
- âœ… ê²°ê³¼:
  ```python
  [ True, True, True, True, True ]
  ```

### ğŸ“Œ ì •ë¦¬

> keep="first" â†’ ì²« ë²ˆì§¸ë§Œ False, ë‚˜ë¨¸ì§€ True

> keep="last" â†’ ë§ˆì§€ë§‰ë§Œ False, ë‚˜ë¨¸ì§€ True

> keep=False â†’ ë™ì¼ í‚¤ ì „ë¶€ True

> **keepì€ â€œTrue/Falseê°€ ì¤‘ë³µ ì—¬ë¶€â€ì´ì§€ â€œì‚­ì œí•  í–‰â€ê³¼ 1:1ë¡œ ë§¤ì¹­ë˜ëŠ” ê±´ ì•„ë‹˜** (**`ì‚­ì œ`ëŠ” `drop_duplicates()`ì—ì„œ ì‹¤í–‰ë¨)**


### 3-2. `drop_duplicates()` ë„ ê°™ì€ ì¸ì
`drop_duplicates(subset=...,keep=...)`ëŠ” ìœ„ ë¡œì§ì„ ê·¸ëŒ€ë¡œ "ì‚­ì œ"ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.

#### 1) ì™„ì „ ì¤‘ë³µë§Œ ì œê±°
```python
people_no_full_dup = people.drop_duplicates() # subset=None, keep="first"
```

#### 2) í‚¤ ê¸°ì¤€, ìµœì‹ ë§Œ ë‚¨ê¸°ê³  ì´ì „ ë²„ì „ ì‚­ì œ
ì‹¤ë¬´ ìµœë¹ˆ ì‹œë‚˜ë¦¬ì˜¤, `updated_at` ì´ ê°€ì¥ ìµœì‹ ì¸ 1ê±´ë§Œ ë‚¨ê¸°ê¸°.
```python
# 1) ìµœì‹ ë¶€í„° ì •ë ¬
people_sorted = people.sort_values("updated_at")  # ì˜¤ë˜ëœâ†’ìµœì‹ , í•„ìš”ì‹œ ascending=True/False ì¡°ì •

# 2) í‚¤ ê¸°ì¤€ ë§ˆì§€ë§‰ë§Œ ë‚¨ê¸°ê¸° â†’ ìµœì‹ ë§Œ ìœ ì§€
people_latest = people_sorted.drop_duplicates(subset=key, keep="last")

# ê²€ì¦: í‚¤ ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ ì—†ìŒ
assert people_latest.duplicated(subset=key).sum() == 0
```

#### 3) ëª¨ë“  ì¤‘ë³µ í–‰ë§Œ ë”°ë¡œ ë³´ê³  ì‹¶ë‹¤ë©´
```python
only_dups = people[ people.duplicated(subset=key, keep=False) ].copy()
```
> ì‹¤ë¬´ íŒ

> - "ìµœì‹ ë§Œ ë‚¨ê¸°ê¸°"ëŠ” ì •ë ¬ ê¸°ì¤€ì´ ì¤‘ìš”í•©ë‹ˆë‹¤. ë³´í†µ `updated_at DESC` â†’ keep="first"ë¡œë„ êµ¬í˜„í•©ë‹ˆë‹¤.
  ```python 
  people_latest = (
    people.sort_values("updated_at", ascending=False)
          .drop_duplicates(subset=key, keep="first")
   )
  ```

#### 4) "ë¶€ë¶„ ì¤‘ë³µ" ë³‘í•©(í†µê³„ì  ì§‘ê³„)
í‚¤ëŠ” ê°™ì§€ë§Œ ìˆ˜ì¹˜ê°€ ë‹¤ë¥´ë©´ **ë¹„ì¦ˆë‹ˆìŠ¤ ë£°**ë¡œ ê²°í•©í•©ë‹ˆë‹¤. (ì˜ˆ : í‚¤ëŠ” `max`, ëª¸ë¬´ê²ŒëŠ” `mean`)
```python
agg_rule = {"height": "max", "weight": "mean"}
people_merged = (
    people.groupby(key, as_index=False)
          .agg(agg_rule)
)

# ê²€ì¦
assert people_merged.duplicated(subset=key).sum() == 0
```
> ì£¼ì˜(SettingWithCopyWarning íšŒí”¼)

> - "ë¶€ë¶„ ì—…ë°ì´íŠ¸ëŠ” í•­ìƒ `.loc[ì¡°ê±´,"col"] = ê°’` í˜•íƒœë¡œ í•˜ëŠ”ê²Œ ì¢‹ìŠµë‹ˆë‹¤.
> - "ì¤‘ê°„ í•„í„°ë§ í›„ ìˆ˜ì •í•˜ë ¤ë©´, `.copy()` ë¡œ ëª…ì‹œì  ë³µì‚¬ë³¸ì„ ë§Œë“¤ì–´ ì—…ë°ì´íŠ¸ í•˜ì‹œë©´ ë©ë‹ˆë‹¤.

### ë§ˆë¬´ë¦¬
ë°ì´í„° í´ë¦¬ë‹ì˜ í•µì‹¬ì€ **ë°ì´í„° íƒ€ì…, ê°’ì˜ ë²”ìœ„, ì¤‘ë³µ ì—¬ë¶€** ë¥¼ ì² ì €íˆ ì ê²€í•˜ê³ , ìƒí™©ì— ë§ëŠ” ì²˜ë¦¬ ë°©ì‹ì„ ì„ íƒí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

| ë¬¸ì œ ìœ í˜•  | ì£¼ìš” ì›ì¸                  | ì²˜ë¦¬ ë°©ë²• ì˜ˆì‹œ                                |
| ------ | ---------------------- | --------------------------------------- |
| íƒ€ì… ì˜¤ë¥˜  | CSV íŒŒì‹±, ì˜ëª»ëœ ì…ë ¥, ë¬¸ìì—´ ìˆ«ì | `.astype()`, `.to_datetime()`           |
| ë²”ìœ„ ì´ˆê³¼  | ì…ë ¥ ì‹¤ìˆ˜, ì‹œìŠ¤í…œ ì˜¤ë¥˜          | í•„í„°ë§, í•˜ë“œ ë¦¬ë°‹, NaN ì²˜ë¦¬                      |
| ì¤‘ë³µ ë°ì´í„° | ë°ì´í„° ë³‘í•©, ì…ë ¥ ì¤‘ë³µ          | `.drop_duplicates()`, `groupby().agg()` |


<hr>

## ğŸ“ Pythonìœ¼ë¡œ ì¹´í…Œê³ ë¦¬ & í…ìŠ¤íŠ¸ ë°ì´í„° í´ë¦¬ë‹ ì™„ë²½ ê°€ì´ë“œ

### 1. Membership Contraints (ì¹´í…Œê³ ë¦¬ ê°’ ìœ íš¨ì„± ì œì•½)

<img width="1193" height="280" alt="image" src="https://github.com/user-attachments/assets/f66d728e-ac21-4f46-846c-008d1be93c74" />

#### 1-1. ë¬¸ì œ ê°œë…
- **ì¹´í…Œê³ ë¦¬ ë°ì´í„°** : ê²°í˜¼ ìƒíƒœ, í˜ˆì•¡í˜•, ëŒ€ì¶œ ìƒíƒœ ë“± â†’ ì‚¬ì „ì— ì •ì˜ëœ ìœ í•œí•œ ê°’ë§Œ í—ˆìš©ë¨
- ë¬¸ì œ ë°œìƒ ì›ì¸:
    - ììœ  ì…ë ¥(Free text) vs ë“œë¡­ë‹¤ìš´ ë¶ˆì¼ì¹˜
    - íŒŒì‹± ì˜¤ë¥˜
    - ì˜ëª»ëœ ê°’ ì…ë ¥
  
<img width="1046" height="350" alt="image" src="https://github.com/user-attachments/assets/0692a165-b2b1-4c89-9531-7afe8a44d6d5" />


#### 1-2. ìœ íš¨ì„± ê²€ì¦ & ì˜ëª»ëœ ê°’ ì°¾ê¸°

```python
import pandas as pd

# ì˜ˆì‹œ ë°ì´í„°
study_data = pd.DataFrame({
    "name": ["Alice", "Bob", "Chris"],
    "blood_type": ["A+", "B-", "Z+"]  # Z+ëŠ” ì˜ëª»ëœ ê°’
})

categories = pd.DataFrame({
    "blood_type": ["A+", "A-", "B+", "B-", "AB+", "AB-", "O+", "O-"]
})

# í—ˆìš©ë˜ì§€ ì•ŠëŠ” ê°’ ì°¾ê¸°
invalid_values = set(study_data["blood_type"]) - set(categories["blood_type"])
# invalid_values = set(study_data["blood_type"]).difference(categories["blood_type"])
print(invalid_values)  # {'Z+'}

# ì˜ëª»ëœ í–‰ í•„í„°ë§ (anti join íš¨ê³¼)
invalid_rows = study_data[study_data["blood_type"].isin(invalid_values)]

# ìœ íš¨í•œ ê°’ë§Œ ë‚¨ê¸°ê¸°
valid_rows = study_data[~study_data["blood_type"].isin(invalid_values)]
```

> ğŸ’¡ Tip

> ì¹´í…Œê³ ë¦¬ ê°’ ëª©ë¡ì€ ë³„ë„ í…Œì´ë¸”/ë¦¬ìŠ¤íŠ¸ë¡œ ê´€ë¦¬í•˜ë©´ ìœ ì§€ë³´ìˆ˜ê°€ ì‰½ìˆ©ë‹ˆë‹¤.

> `isin`ì€ Membership Check í•µì‹¬ í•¨ìˆ˜!

### 2. Categorical Variables(ì¹´í…Œê³ ë¦¬ ê°’ í‘œì¤€í™”)

#### 2-1. ëŒ€ì†Œë¬¸ì/ê³µë°± ë¬¸ì œ

```python
demographics = pd.DataFrame({"marriage_status": ["Married", "unmarried", " married ", "UNMARRIED"]})

# Get marriage status column
marriage_status = demographics['marriage_status']
marriage_status.value_counts()

'''
unmarried 352
married   268
MARRIED   204
UNMARRIED 176
dtype : int64
'''
```
> `.value_counts()` ë©”ì„œë“œëŠ” Series ì—ë§Œ ì‘ë™í•©ë‹ˆë‹¤.

```python
# Get value counts on DataFrame
m = demographics.groupby('marriage_status')
m.count()
```
> DataFrame ê²½ìš°, ì—´ì„ ê¸°ì¤€ìœ¼ë¡œ ê·¸ë£¹í™”í•˜ê³  `.count()` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


- **ëŒ€/ì†Œë¬¸ì ë³€í™˜**


```python
# ëŒ€/ì†Œë¬¸ì ë³€í™˜
marriage_status["marriage_status"] = marraige_status["marriage_status"].str.upper()
marriage_status["marriage_status"].value_counts()

marriage_status["marriage_status"] = marriage_status["marriage_status"].str.lower()
marriage_status["marriage_status"].value_counts()

'''
UNMARRIED  528
MARRIED  472
'''
```

- **Trailing spaces** : `married `,`married`,`unmarried`,` unmarried `,...

```python
# ì•ë’¤ ê³µë°± ì œê±°
marriage_status = demographics["marriage_status"]
marriage_status.value_counts()

marriage_status["marriage_status"] = marriage_status["marriage_status"].str.strip()
'''
unmarried 352
married   268
MARRIED   204
UNMARRIED 176
dtype : int64
'''

# Strip all spaces
demographics = demographics["marriage_status"].str.strip()
demographics["marriage_status"].value_counts()

'''
unmarried 528
married   472
'''
```

#### 2-2. êµ¬ê°„ë³„ ë²”ì£¼í™”(`cut` vs `qcut`)

- **`qcut`**: ë¶„ìœ„ìˆ˜ ê¸°ë°˜ êµ¬ê°„ -> `ìƒëŒ€í‰ê°€` ë¼ê³  ìƒê°í•˜ë©´ ì‰½ìŠµë‹ˆë‹¤!
```python
import numpy as np
import pandas as pd

group_names = ['0-200K','200K-500K','500K+']
demographics['income_group'] = pd.qcut(demographics['household_income'], q=3, labels = group_names)

# print income_group column
demographics[['income_group', 'household_income']]

'''
         category    household_income
0      200K-500K      189243
1          500K+      778533
'''
```

- **`cut`** : ê³ ì • êµ¬ê°„ -> `ì ˆëŒ€í‰ê°€` ë¼ê³  ìƒê°í•˜ë©´ ì‰½ìŠµë‹ˆë‹¤!
```python
# Using cut() - create category ranges and names

ranges = [0,200000,500000,np.inf]
group_names = ['0-200K','200K-500K','500K+']

# Create income group column
demographics['income_group'] = pd.cut(demographics['household_income'], bins=ranges, labels = group_names)
demographics[['income_group', 'household_income']]

'''
         category    household_income
0         0-200K      189243
1          500K+      778533
'''
```

> `cut` â†’ ê·œì¹™/ê¸°ì¤€ í™•ì‹¤í•  ë•Œ : ì ˆëŒ€í‰ê°€

<img width="969" height="336" alt="image" src="https://github.com/user-attachments/assets/20756f8c-f8a3-4728-9568-bcf925c599c1" />

> `qcut` â†’ ë°ì´í„° ë¶„í¬ì— ë§ì¶° ê· ë“± ê°œìˆ˜ë¡œ ë‚˜ëˆŒ ë•Œ : ìƒëŒ€í‰ê°€

<img width="960" height="458" alt="image" src="https://github.com/user-attachments/assets/25689dc4-8fc9-4e59-94be-dc37a658e62c" />

#### 2-3. ë²”ì£¼ ì¶•ì†Œ(ì¹´í…Œê³ ë¦¬ ë§¤í•‘)

```python
os_map = {
    "Windows": "DesktopOS",
    "MacOS": "DesktopOS",
    "Linux": "DesktopOS",
    "Android": "MobileOS",
    "iOS": "MobileOS"
}

df["os_type"] = df["os_name"].replace(os_map)
df["os_type"].unique()

'''
array(['DesktopOS','MobileOs'],dtype=object)
'''
```

> 'DektopOs' ì™€ 'MobileOs' ì¹´í…Œê³ ë¦¬ë¡œ 2ê°œë¡œ ì¶•ì†Œí•˜ê³  ì‹¶ë‹¤ë©´, mappingì„ í™œìš©í•˜ë©´ ë©ë‹ˆë‹¤. í‚¤-ê°’ í˜•íƒœì˜ ë§¤í•‘ì„ í™œìš©í•´ì„œ, "os_type" ì´ë¼ëŠ” ì»¬ëŸ¼ì— ê° ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì¶•ì†Œ-ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


- (ex)
```python
# Create ranges for categories
label_ranges = [0, 60, 180, np.inf]
label_names = ['short', 'medium', 'long']

# Create wait_type column
airlines['wait_type'] = pd.cut(airlines['wait_min'], bins = label_ranges, 
                                labels = label_names)

# Create mappings and replace
mappings = {'Monday':'weekday', 'Tuesday':'weekday', 'Wednesday': 'weekday', 
            'Thursday': 'weekday', 'Friday': 'weekday', 
            'Saturday': 'weekend', 'Sunday': 'weekend'}

airlines['day_week'] = airlines['day'].replace(mappings)
```
<img width="1187" height="276" alt="image" src="https://github.com/user-attachments/assets/4039158d-09fe-491f-87b6-8ec015499657" />


### 3. Cleaning Text Data(ë¬¸ìì—´ ì •ë¦¬)

#### 3-1. ê¸°ë³¸ ë¬¸ìì—´ ì¹˜í™˜

```python
import numpy as np

phones = pd.DataFrame({
    "full_name": ["Alice Smith", "Bob Lee", "Chris Kim"],
    "phone": ["+8210-1234-5678", "0044-20-1234-5678", "1234"]
})

# '+' â†’ '00'
phones["phone"] = phones["phone"].str.replace("+", "00", regex=False)

# '-' ì œê±°
phones["phone"] = phones["phone"].str.replace("-", "", regex=False)

# ê¸¸ì´ < 10 â†’ NaN
phones.loc[phones["phone"].str.len() < 10, "phone"] = np.nan
```

#### 3-2. ì •ê·œí‘œí˜„ì‹(Regex)ìœ¼ë¡œ ìˆ«ìë§Œ ì¶”ì¶œ

```python
# ìˆ«ìê°€ ì•„ë‹Œ ëª¨ë“  ë¬¸ì ì œê±°
phones["phone_digits"] = phones["phone"].str.replace(r"\D", "", regex=True)
```
> `\D` = ìˆ«ìê°€ ì•„ë‹Œ ë¬¸ì

> `\d` = ìˆ«ì

> `regex=True` ì˜µì…˜ í•„ìˆ˜

#### 3-3. ë°ì´í„° ê²€ì¦(Assert)

```python
# ìµœì†Œ ê¸¸ì´ 10 ì´ìƒ í™•ì¸
assert phones["phone_digits"].str.len().min() >= 10

# '+' ë˜ëŠ” '-' ì¡´ì¬ ì—¬ë¶€ í™•ì¸
assert not phones["phone_digits"].str.contains(r"[\+\-]", regex=True).any()
```

### 4. ì‹¤ë¬´ ì²´í¬ë¦¬ìŠ¤íŠ¸

| ë¬¸ì œ ìœ í˜•       | ì£¼ìš” ì›ì¸                  | ì²˜ë¦¬ ë°©ë²• ì˜ˆì‹œ                       |
| ----------- | ---------------------- | ------------------------------ |
| ì˜ëª»ëœ ì¹´í…Œê³ ë¦¬ ê°’  | ì…ë ¥ ì˜¤ë¥˜, íŒŒì‹± ì‹¤íŒ¨           | `isin` / anti join / ë§¤í•‘        |
| ëŒ€ì†Œë¬¸ìÂ·ê³µë°± ë¶ˆì¼ì¹˜ | ìˆ˜ë™ ì…ë ¥, ì‹œìŠ¤í…œ ë³‘í•© ì‹œ í¬ë§· ê¹¨ì§  | `.str.lower()`, `.str.strip()` |
| ì¹´í…Œê³ ë¦¬ ê³¼ë‹¤     | ë””ë°”ì´ìŠ¤, ì œí’ˆêµ° ë“± ì„¸ë¶„í™” ì§€ë‚˜ì¹¨    | ë§¤í•‘(í†µí•©)                         |
| ë¬¸ìì—´ í˜•ì‹ ë¶ˆì¼ì¹˜  | ì „í™”ë²ˆí˜¸, ìš°í¸ë²ˆí˜¸, ID ë“± ê·œê²© ê¹¨ì§ | `.str.replace()`, Regex        |


### ğŸ“Œ ë§ˆë¬´ë¦¬

- **Membership Check**ë¡œ ìœ íš¨í•œ ê°’ë§Œ í—ˆìš©
- **í¬ë§· í‘œì¤€í™”**(ëŒ€ì†Œë¬¸ì, ê³µë°±, ê¸°í˜¸)ë¡œ ì§‘ê³„ ì •í™•ë„ í–¥ìƒ
- **ë²”ì£¼í™” & ë²”ì£¼ ì¶•ì†Œ**ë¡œ ë¶„ì„ ê°€ë…ì„± ë° ëª¨ë¸ ì•ˆì •ì„± í™•ë³´
- **ì •ê·œí‘œí˜„ì‹**ìœ¼ë¡œ íŒ¨í„´ ê¸°ë°˜ ë¬¸ìì—´ ì •ë¦¬
- **Assert** ë¬¸ìœ¼ë¡œ í’ˆì§ˆ ë¶ˆë³€ì‹ ìœ ì§€










































## Snowflake : 클라우드 기반 데이터 웨어하우스
- Snowflake는 **클라우드 기반 데이터 웨어하우스** 로, **컬럼형(Columnar) 데이터 저장 방식** 을 활용하여 고성능 데이터 분석을 가능하게 한다.
- AWS, Google Cloud, Microsoft Azure 등 다양한 클라우드 제공업체와 통합이 가능하며, **확장성** 과 **비용 효율성** 이 뛰어나다.

## 1. Snowflake
- Snowflake는 **클라우드에서 운영되는 데이터 웨어하우스** 이다.
- **컬럼형(Columnar) 데이터 저장 방식** 을 사용하여 분석 성능을 최적화한다.
- 클라우드 기반으로 유지보수를 부담 없이 확장할 수 있다.

- 핵심 특징
    - 완전한 **클라우드 네이티브(Cloud-Native)** 솔루션 이다.
    - 자동확장(Auto Scailing) 및 고성능 쿼리 처리가 가능하다.(컬럼 저장 방식 활용하므로)
    - **서버리스(Serverless)구조** (클라우드) 로 유지보수 부담이 없다.
    - **멀티 클라우드를 지원** 한다. (AWS, GCP, Azure 와 통합 가능)
    - **데이터 공유 기능(Data Sharing)** 을 지원한다.
    
## 2. 클라우드 데이터 웨어하우스의 개념 

- 클라우드 데이터웨어하우스의 장점
    - 하드웨어 구매 불필요 -> 초기 비용이 절감된다.
    - 사용량 기반 과금(Pay-as-you-go) -> 비용을 최적화할 수 있다.
    - 글로벌 접근성 -> 여러 지역에서 동시 데이터 사용이 가능하다.
    - 자동 확장(Auto Scailing) -> 데이터 증가에 유연한 대응이 가능하다.

- Snowflake 는 이러한 클라우드 데이터 웨어하우스의 강점을 극대화한 솔루션이다.

## 3. Row vs Columnar 데이터 저장 방식

- Snowflake 는 Columnar 데이터 저장 방식을 사용한다.
- 전통적인 데이터베이스(ex.PostgreSQL)는 행 기반(Row-Oriented) 저장 방식을 사용한다.

### Row-Oriented Storgae (행 기반 저장)
![Image](https://github.com/user-attachments/assets/ea9dd5ec-7afa-4050-a662-5635ba82967a)
![Image](https://github.com/user-attachments/assets/8b70564a-f0d3-429a-b96d-8739f6b518a9)

- 데이터를 행(Row) 단위로 저장
- **트랜잭션(OLTP)** 작업에 최적화(ex. 주문처리, CRUD 작업)
  
- 장점
    - 빠른 개별 레코드 조회가 가능하다.
    - 삽입 및 수정 작업에 최적화 되어있다.
- 단점
    - 특정 컬럼만 조회하는 분석 쿼리가 비효율적이다. (불필요한 데이터도 함께 로드된다.)

### Columnar Storage(열 기반 저장)
![Image](https://github.com/user-attachments/assets/ea9dd5ec-7afa-4050-a662-5635ba82967a)
![Image](https://github.com/user-attachments/assets/8e0b1810-ab27-4f39-bef3-6854679fa668)

- 데이터를 컬럼(Column) 단위로 저장
- **데이터 분석(OLAP)** 작업에 최적화(ex. 매출평균 계산)
  
- 장점
    - 특정 컬럼만 조회가 가능하다. -> 분석 성능이 향상된다.
    - 데이터 압축 효율이 증가한다. -> 저장 공간이 절약된다.
- 단점
    - 트랜잭션 작업이 상대적으로 느리다.

- Snowflake 는 컬럼 저장 방식을 활용하여 분석 성능을 극대화한다.

### Row vs Column DB 비교
![Image](https://github.com/user-attachments/assets/3faa47e2-3741-4426-b3b1-0cf4a26c3266)

## 4. Snowflake 의 주요 활용 사례
- Business Intelligence
- Data Science 
- Data Ingestion : 다양한 data source에서 데이터를 스트리밍, 배치 등의 방식으로 추출하여 data warehouse로 적재하는 것을 의미
- Data Warehousing
- Data Sharing

<hr>

## Snowflake 아키텍처 : 클라우드 데이터 웨어하우스의 구조 분석
- Snowflake 는 **스토리지(Storage)** 와 **컴퓨팅(Computing)** 을 **분리** 하는 아키텍처를 채택하여 확장성과 성능을 극대화한 **클라우드 기반 데이터 웨어하우스** 이다.

## Snowflake 의 아키텍처 개요
- Snowflake는 하이브리드 아키텍처를 사용한다.
- 스토리지(Shared-Disk) 와 컴퓨팅(Shared-Nothing) 을 분리하여 독립적인 확장이 가능하다.
- 3가지 주요 레이어로 구성된다.
    - 스토리지(Storage) 레이어 : 데이터를 **컬럼 기반으로 저장하고 최적화** 한다.
    - 컴퓨팅(Computing) 레이어 : 쿼리를 실행하는 **가상 웨어하우스(Virtual Warehouse)**
    - **클라우드 서비스(Cloud Services)** 레이어 : 보안, 관리, 메타데이터 처리

### 기존 데이터베이스 아키텍처와 Snowflake의 차이점
1. Shared-Disk 아키텍처
   
![Image](https://github.com/user-attachments/assets/8245e144-0675-4297-9e29-ad7ce4d55528)
    
- 모든 노드(Node)가 **공유 스토리지(Storage)** 를 사용한다.
- 데이터가 중앙 저장소에 있어, **모든 노드가 동일한 데이터에 접근이 가능** 하다.
- 노드가 증가할수록 **동시 접근 문제(Contention)** 가 발생할 수 있다.
- (ex) Oracle RAC, IBM Db2

2. Shared-Nothing 아키텍처
   
![Image](https://github.com/user-attachments/assets/d55420fe-968a-404a-bf71-158383b3f0d3)
    
- **스토리지와 컴퓨팅을 완전히 분리** 한다.
- 각 노드가 **자신만의 독립적인 디스크와 컴퓨팅 리소스를 보유** 한다.
- 병렬 처리(Parallel Processing)에 강점이 있지만, **데이터 이동이 필요할 경우 성능 저하** 가 발생할 수 있다.
- (ex) Hadoop, Amazon Redshift

### Snowflake 는 하이브리드 아키텍처

![Image](https://github.com/user-attachments/assets/94a461f9-3922-41c2-a48f-6ad544dc201e)

- **Snowflake는 Shared-Disk와 Shared-Nothing 구조를 결합한 하이브리드 아키텍처** 이다!
- 모든 데이터를 중앙 집중화하는 **공유 스토리지(Storage) 계층에 있는** 반면,
- **컴퓨팅은 독특하게 분리**되어 있다. 

## 1. 스토리지(Storage) 레이어 
![Image](https://github.com/user-attachments/assets/7582d245-f1bd-4e9e-8af9-56f54b5911db)

- Snowflake 는 데이터를 컬럼(Columnar) 형식으로 저장한다.
- 자동 압축 및 최적화를 수행한다.(사용자가 직접 데이터 정리를 할 필요가 없다.)
    
    - 스토리지의 주요 기능
        - 데이터를 자동으로 정리한다.(Partioning & Clustering) -> 데이터에 접근 및 분석을 용이하게 해준다.
        - 데이터 압축(Compression) 최적화(컬럼 형식으로 저장하므로)
        - **테이블(Table), 스키마(Schema), 데이터베이스(Database)** 로 구성된다. -> 필요한 정보를 더 쉽게 관리하고 검색할 수 있게 해준다.
        - 사용자가 직접 스토리지를 관리하지 않아도 **Snowflake가 내부적으로 최적화**

- 컬럼 기반 저장 방식 덕분에 쿼리 성능이 크게 향상된다!

## 2. 컴퓨팅(Compute) 레이어 : 가상 웨어하우스(Virtual Warehouse)
![Image](https://github.com/user-attachments/assets/924775ce-269d-4608-ab4e-09ffe165e641)

- Snowflake에서 Compute layer 는 **쿼리가 수행되며 값진 인사이트로 전환되는 마법과 같은 엔진룸** 이라고 보면 된다. -> Query Processing
- Snowflake는 이를 달성하기 위해 **가상 웨어하우스** 를 사용한다.

- 가상 웨어하우스(Virtual Warehouse) 란?
    - Snowflake 에서 쿼리를 실행하는 **임시 컴퓨팅 리소스**를 말한다. -> 쿼치 처리를 위해 특별히 설계된 컴퓨터 팀이라고 보면 된다.
    - 사용자가 쿼리를 실행하면 Snowflake는 **필요한 컴퓨팅 리소스를 동적으로 할당** 한다.

    - 가상 웨어하우스의 주요 기능
        - **자동 확장(Auto Scaling)** : 필요한 만큼 리소스를 늘리거나 줄일 수 있다.
        - **병렬 처리(Parallel Processing)** : 여러 가상 웨어하우스가 동시에 실행 가능하다.
        - **사용량 기반 과금(Pay-as-you-go)** : 사용한 만큼 비용을 지불한다.

- 가상 웨어하우스를 활용하면, 원하는 성능에 맞게 Snowflake 를 조절할 수 있다!

## 3. 클라우드 서비스(Cloud Services) 레이어
![Image](https://github.com/user-attachments/assets/50508542-bab0-49d6-8933-a1e74a29c3c5)

- Cloud layer 는 쿼리를 실행할 때 올바른 리소스외 컴퓨팅과 저장이 효율적으로 더 빠른 결과를 얻도록 보장한다. 
- 클라우드 서비스 레이어는 Snowflake 의 관리 및 보안 기능을 담당한다. -> 지휘자 역할을 하며 모든 것을 조정하는 계층

    - 클라우드 서비스의 주요 기능
        - **쿼리 최적화(Query Optimization)** : 실행 계획(Execution Plan) 최적화 -> Optimizer
        - **보안(Security)** : 사용자 인증, 암호화 관리 
        - **데이터 액세스 관리** : 데이터 공유(Data Sharing) 및 접근 제어
        - **메타데이터 관리** : 테이블, 인덱스, 스키마 정보 유지

- Snowflake의 클라우드 서비스는 **사용자의 개입 없이 모든 관리 작업을 자동으로 처리** 한다!


![Image](https://github.com/user-attachments/assets/2f211277-4a85-4da3-83a3-5e4ea1c1e1a0)


## Snowflake 아키텍처의 주요 장점 및 결론
1. 스토리지와 컴퓨팅의 완전한 분리
    - 사용자는 필요한 만큼의 컴퓨팅 리소스만 할당하여 비용 절감이 가능하다.
2. 고성능 데이터 처리
    - 컬럼 저장 방식과 자동 최적화를 통해 대용량 데이터 쿼리 속도가 향상된다.
3. 자동 확장(Auto Scaling)
    - 가상 웨어하우스를 확장하여 동시 사용자 증가에도 성능 유지가 가능하다.
4. 사용량 기반 과금(Pay-as-yo-go)
    - 스토리지와 컴퓨팅 비용을 따로 청구하여 비용을 최적화한다.
5. 멀티 클라우드를 지원한다.
    - AWS, Google Cloud, Azure 에서 모두 사용이 가능하다.

- Snowflake 는 클라우드 환경에서 데이터 분석을 최적화한 강력한 솔루션이다!

<hr>

## Snowflake 와 경쟁 데이터 플랫폼 비교 및 차별점
- Snowflake 와 Google BigQuery, Amazon Redshift, Databricks 및 PostgreSQL 을 비교하고 차별점과 장점을 살펴보자.

## Snowflake 의 주요 경쟁 플랫폼
![Image](https://github.com/user-attachments/assets/1aba97cf-ba2d-4589-b469-105c407b92dd)

- 클라우드 데이터 웨어하우스
    - **Google BigQuery**, **Amazon Redshift**, **Databricks** 등이 있다.

- 온프레미스(자체 구축형) 데이터베이스
    - **PostgreSQL**

## 아키텍처(Architecture) 비교
![Image](https://github.com/user-attachments/assets/ffd7b152-fd06-4918-aaa5-880582d92c2a)

- Snowflake, BigQuery, Databricks 는 스토리지와 컴퓨팅을 분리하여 **유연한 확장이 가능** 하다.
- Redshift는 기본적으로 결합된 구조이나 일부 옵션에서는 분리가 가능하다.
- PostgreSQL은 온프레미스 환경에서 운영되며 확장성이 제한된다.

## 확장성(Scalability) 비교
![Image](https://github.com/user-attachments/assets/6dd6cf4a-54f7-4212-a9fd-a4e60291a99a)

- Snowflake, BigQuery, Databricks 는 **자동확장(AutoScaliing)을 지원하여 성능 최적화가 가능** 하다.
- Redshift는 확장이 가능하지만, 다소 딜레이가 발생할 수 있다.
- PostgreSQL은 확장이 어렵고, 수동으로 클러스터링 해야 한다.

## 관리 부담(Management) 비교
![Image](https://github.com/user-attachments/assets/0f77880e-568a-45aa-838e-55b7244a04a3)

- Snowflake와 BigQuery는 자동화된 관리 기능으로 운영 부담이 적다.
- Databricks, Redshift 는 일부 관리 작업이 필요하다.
- PostgreSQL은 직접 관리해야 하므로 유지보수 부담이 크다.

## 보안(Security) 비교
- 모든 플랫폼은 **암호화(Encryption) 및 접근 제어(Access Control)** 기능을 제공한다.
- 데이터 보호 방식은 각 플랫폼마다 다르다.

## 데이터 지원(Data Support) 비교
![Image](https://github.com/user-attachments/assets/79d36503-d63d-45b5-af80-4b21d2c21d55)

- Databricks는 **비정형(Un-Structured) 데이터까지 지원** 하여 머신러닝 및 AI 작업에 유리하다.
- Snowflake, BigQuery, Redshift 는 주로 **구조화 및 반구조화** 데이터 처리에 최적화되어 있다.
  
## 클라우드 통합(Integration) 비교
![Image](https://github.com/user-attachments/assets/4bfbca63-dd82-4a2c-8b00-5ee2b7191641)

- Snowflake, BigQuery 는 AWS,GCP,Azure 모두 지원하여 **유연한 멀티 클라우드 운영이 가능** 하다.
- BigQuery는 GCP 중심이지만, **일부 클라우드 연결 기능을 제공** 한다.
- Redshift는 **AWS 전용 서비스** 이다.

## 가격 정책(Pricing) 비교

- Snowflake : 사용량 기반 과금(Pay-as-you-go) -> 유연한 사용량 기반 과금 모델로 비용 최적화가 가능하다.
- BigQuery : 데이터 처리량 기반 과금(온디맨드 또는 **슬롯** 기반) -> 데이터 처리량을 기준으로 가격이 결정된다.
- Databricks : VM 및 컴퓨팅 리소스 사용량 기반
- Redshift : 스토리지 및 컴퓨팅 비용 분리 가능(기본은 통합)
- PostgreSQL : 오픈소스(무료)지만, **클라우드 호스팅 시 비용발생** -> 자체 운영 시 무료이지만, 클라우드에서 실행하면 비용이 발생한다. 

## Snowflake VS PostgreSQL
- SnowflakeSQL은 ANSI(American National Standard Institute) SQL 기반으로 **PostgreSQL과 유사한 문법을 사용** 한다.
- 기본적인 SQL 쿼리는 PostgreSQL 과 **동일하게 작동** 한다.
- 일부 함수 및 기능에서 차이가 있지만, PostgreSQL 사용자는 쉽게 적응이 가능하다.
- (ex)
```SQL
SELECT * FROM orders;
```
- PostgreSQL과 SnowflakeSQL에서 **동일하게 실행 가능** 하다!

<hr>

## Snowflake 연결 방법 및 DDL 명령어 정리

## Snowflake 연결방법
1. **Snowsight(웹 인터페이스)**
- Snowsight 는 Snowflake의 공식 웹 인터페이스이다.
- SQL 실행 및 데이터베이스 관리가 가능하다.
- **GUI 기반** 으로 사용이 간편하다.
- 워크시트(Worksheets)에서 SQL 실행이 가능하다.
- 데이터베이스, 스키마, 테이블, 뷰를 탐색할 수 있다.
- 가장 쉽게 Snowflake에 접속할 수 있는 방법이다!

2. **ODBC/JDBC 드라이버(외부 툴 연결)**
- ODBC(Open Database Connectivity) 및 JDBC(Java Database Connectivity) 드라이버를 지원한다.
- 연결 가능한 툴로는 DB Visualizer, Tableau, Power BI 등이 있다.
- Python, Java 등의 프로그래밍 언어에서도 Snowflake 데이터 활용이 가능하다.
- Snowflake 데이터를 **외부 BI 및 애플리케이션에서 활용이 가능** 하다!

3. **SnowSQL(CLI 기반 연결)**
- SnowSQL은 **Snowflake 전용 커맨드라인 인터페이스(CLI)** 이다.
- Snowflake 설치 후 **터미널에서 직접 Snowflake에 접속이 가능** 하다.
- PostgreSQL 의 psql 과 유사한 명령어 환경을 제공한다.
- 배치 작업, 자동화 스크립트 실행 등에 유용하다.
- (ex) SnowSQL을 사용한 Snowflake 연결 : snowsql -a <account_name> -u <username>
- **개발자 및 데이터 엔지니어가 선호하는 방법** 이다!

## Staging 개념 및 데이터 로딩 과정

### 1. Staging 이란?
- Staging 은 데이터 로딩 전 **임시 저장 공간** 을 말한다.
- **로컬 또는 클라우드 스토리지** 에서 **Snowflake 로 데이터를 이동할 때 사용** 한다.

- Staging의 종류
    - **Internal Stage : Snowflake 내부에 저장**되는 데이터
    - **External Stage** : Amazon S3, Google Cloud Storage 등 **외부 스토리지에 저장** 된 데이터

- 데이터 로딩 과정

  ![Image](https://github.com/user-attachments/assets/1790786a-bfee-4bdb-8fe8-8a60f0102945)
    
    - CSV 또는 JSON 등의 **원본 데이터 파일을 Staging에 업로드**
    - **COPY 명령어를 사용해 Snowflake 테이블로** 이동

### 2. CREATE Stage(스테이징 생성)
- CREATE STAGE 명령어로 스테이징을 생성한다.

(ex) orders.csv 파일을 위한 내부 스테이징 생성
```SQL
CREATE STAGE my_stage;
```
(ex) PUT 명령어를 사용해 파일 업로드
```SQL  
PUT file://orders.csv @my_stage;
```
(ex) COPY 명령어로 테이블로 데이터 이동    
```SQL
COPY INTO orders FROM @my_stage;
```       

### 3. Snowflake DDL(Data Defintion Language) 명령어
- CREATE TABLE - 테이블 생성

    (ex) orders_pizza 테이블 생성
    ```SQL
    CREATE TABLE orders_pizza (
        order_id INT PRIMARY KEY,
        customer_id INT,
        pizza_type VARCHAR(50),
        order_date DATE
    ); -- PostgreSQL 과 동일한 문법 사용!
    ```

- ALTER TABLE - 테이블 수정

    (ex) 테이블 이름 변경
    ```SQL  
    ALTER TABLE orders_pizza RENAME TO orders;
    ```
    (ex) 컬럼 이름 변경    
    ```SQL
    ALTER TABLE orders_pizza COLUMN order_date TO order_time;
    ```       
    (ex) 컬럼 추가   
    ```SQL
    ALTER TABLE orders ADD COLUMN delivery_status VARCHAR(20);
    ```
    
- DROP TABLE - 테이블 삭제

    (ex) 테이블 삭제
    ```SQL  
    DROP TABLE orders;
    ```
    (ex) 테이블 존재 시 삭제 (안전 모드)
    ```SQL
    DROP TABLE IF EXISTS orders;
    ```
    
- COMMENT - 주석 추가

    (ex) 컬럼 주석 추가
    ```SQL
    ALTER TABLE pizza_type MODIFY COLUMN pizza_type_id COMMENT 'Unique ID for pizza types';
    ```
    (ex) 테이블 주석 추가
    ```SQL
    CREATE TABLE pizza_type (
    pizza_type_id INT PRIMARY KEY,
    pizza_name VARCHAR(100) COMMENT 'Type of pizza',
    category VARCHAR(50)
    ) COMMENT = 'Stores pizza category details';
    ```       

### Snowflake 의 DDL 명령어는 PostgreSQL과 거의 동일하다. 단, 일부 추가 기능을(ex.Staging, Cloud Storage 연동)제공한다. PostgreSQL 사용자라면, 손쉽게 SnowflakeSQL 을 익힐 수 있다.

<hr>

## Snowflake 데이터베이스 구조 및 DML 명령어 정리

## 1. Snowflake 데이터베이스 탐색

### (1) 데이터베이스 조회 - SHOW DATABASES
- Snowflake에서는 `SHOW` 명령어를 활용하여 데이터베이스 정보를 조회할 수 있다.
```SQL
SHOW DATABASES;
```
- 데이터베이스 이름, 소유자, 주석 등 정보를 확인할 수 있다.

### (2) 테이블 조회 - SHOW TABLES
- 특정 데이터베이스 내 테이블 목록을 확인할 수 있다.
(ex) `pizza_sales` 데이터베이스의 테이블 조회
```SQL
SHOW TABLES IN pizza_sales;
```
(ex) LIKE 연산자를 활용하여 특정 이름의 테이블을 검색할 수 있다.
```SQL
SHOW TABLES LIKE 'PIZZA%';
```

### (3) 스키마 및 컬럼 정보 조회 - SHOW SCHEMA, SHOW COLUMNS
- 데이터베이스 내 스키마 및 테이블의 컬럼 정보를 조회할 수 있다.
- 스키마 조회
```SQL
SHOW SCHEMA IN pizza_sales;
```
- 테이블 내 컬럼 조회
```SQL
SHOW COLUMNS IN TABLE pizza_orders;
```

### (4) 뷰(View) 및 테이블 상세 정보 조회 - SHOW VIEWS, DESCRIBE
- 데이터베이스 내 뷰 목록을 조회할 수 있다.
```SQL
SHOW VIEWS IN pizza_sales;
```
- 특정 테이블 또는 스키마의 상세 정보를 확인할 수 있다.
```SQL
DESCRIBE TABLE pizza_orders;
DESCRIBE DATABASE pizza;
DESCRIBE SCHEMA public;
```
- `DESC` 는 `DESCRIBE` 의 축약형이다.

### (5) STAGE(스테이징) 정보 조회 - DESCRIBE STAGE
- **STAGE** 는 데이터를 Snowflake 로 로딩하기 전 **임시 저장하는 공간** 을 말한다.
- 파일 형식, 구분자, 기본 설정 값을 확인할 수 있다.
(ex) 특정 STAGE의 상세 정보 확인
```SQL
DESCRIBE STAGE my_stage;
```


## 2. DML (데이터 조작어) 명령어

### (1) INSERT - 데이터 삽입
(ex) 명시적인 값 삽입
```SQL
INSERT INTO pizza_orders (order_id, customer_id, pizza_type, order_date)
VALUES (1,1001,'Pepperoni', 2024-02-01');
```
(ex) 쿼리 결과를 활용한 삽입
```SQL
INSERT INTO order_filtered
SELECT * FROM orders WHERE order_date > '2024-01-01';
```
- **PostgreSQL과 동일한 문법** 을 사용한다!

### (2) UPDATE - 데이터 수정
(ex) 특정 조건을 만족하는 데이터를 수정할 수 있다.
```SQL
UPDATE orders
SET order_time = '17:00:00'
WHERE order_id = 5;
```

### (3) MERGE - 두 테이블 동기화
- `MERGE` 는 두 테이블을 비교하여 업데이트 또는 삽입을 수행한다.
(ex) `orders_filtered` 를 `orders` 테이블과 동기화
```SQL
MERGE INTO orders_filtered AS target -- Target table(업데이트 하려는 테이블)
USING orders AS source -- Soruce table
ON target.order_id = source.order_id -- Common column
WHEN MATCHED THEN -- When there is a match(일치 항목이 있으면) update
    UPDATE SET target.order_date = source.order_date, target.order_time = source.order_time
WHEN NOT MATCHED THEN 
    INSERT (order_id, order_date, order_time)
    VALUES (source.order_id, source.order_date, soure.order_time);
```
- `MERGE` 를 활용하면 중복 데이터 없이 최신 상태를 유지할 수 있다.

### (4) COPY INTO - 데이터 로딩
- STAGE에 있는 데이터를 Snowflake 테이블로 로딩하는 명령어
- CSV, JSON, Parquet 등 다양한 파일 포맷을 지원한다.
(ex) `orders.csv` 파일을 `orders` 테이블로 로딩
```SQL
COPY INTO orders
FROM @my_local_stage/orders.csv 
FILE_FORMAT = (TYPE = 'CSV', FILED_OPTIONALLY_ENCLOSED_BY='"');
```
- `@my_local_stage` 는 우리가 이전에 만들었던 stage 를 말한다.
- `orders.csv` 는 우리가 데이터를 복사하는 단계 내의 파일을 말한다.
- `FIEL_FORMAT` 은 원본 데이터 형식(위 예시에서는 CSV)을 정의한다.(다양한 형태 가능)
- `COPY INTO` 를 활용하면 대량 데이터를 빠르게 Snowflake로 로딩할 수 있다.

<hr>

## Snowflake 데이터 타입 및 데이터 타입 변환 정리

## 1. Snowflake의 주요 데이터 타입
- Snowflake는 PostgreSQL 과 유사한 데이터 타입을 제공하지만, 일부 차이점이 있다.
- 특히, `VARIANT` 타입을 제공하여 반구조화 데이터를 저장할 수 있다.

![Image](https://github.com/user-attachments/assets/bba25255-02c8-49a5-b503-744d38616552)

- `VARCHAR`, `NUMERIC`, `INT` 등 PostgreSQL 과 동일하지만, `VARIANT` 는 Snowflake 만의 특징이다!

## 2. PostgreSQL 과의 데이터 타입 비교

![Image](https://github.com/user-attachments/assets/75f3099d-a4cb-4338-a7ac-709dac05f2db)

- `VARCHAR` 의 최대길이가 PostgreSQL 보다 훨씬 크다.
- `NUMERIC` 의 기본 정밀도가 더 높아 소수점 데이터 표현력이 뛰어나다.
- `INT`의 숫자 범위가 더 크다.

## 3. DATE, TIME, TIMESTAMP 데이터 타입

### (1) DATE - 날짜 데이터
- `YYYY-MM-DD` 또는 `DD-MM-YYYY` 형식으로 날짜를 저장할 수 있다.(디폴트는 `YYYY-MM-DD` 형식이다.)
- 다양한 날짜 형식을 인식할 수 있다.

(ex) 주문 날짜 저장
```SQL
CREATE TABLE orders (
    order_id INT PRIMARY KEY,
    order_date DATE
);
```
(ex) 날짜 데이터 삽입
```SQL
INSERT INTO orders (order_id, order_date) VALUES (1,'2024-02-10');
```

### (2) TIME - 시간 데이터
- `HH:MI:SS` 형식으로 시간을 저장할 수 있다.

(ex) 주문 시간 저장
```SQL
CREATE TABLE orders (
    order_id INT PRIMARY KEY,
    order_time TIME
);
```
(ex) 시간 데이터 삽입
```SQL
INSERT INTO orders (order_id, order_time) VALUES (1,'14:30:00');
```

### (3) TIMESTAMP - 날짜 + 시간 데이터
- DATE 와 TIME 을 합친 형태로, 날짜와 시간을 한 번에 저장할 수 있다.

(ex) 주문 시간 저장
```SQL
CREATE TABLE orders (
    order_id INT PRIMARY KEY,
    order_date TIMESTAMP
);
```
(ex) 날짜 데이터 삽입
```SQL
INSERT INTO orders (order_id, order_timestamp) VALUES (1,'2024-02-10 14:30:00');
```
- `TIMESTAMP` 를 활용하면 날짜와 시간을 동시에 관리할 수 있다!

## 4. 데이터 타입 변환
- 데이터 타입 변환은 한 데이터 타입을 다른 타입으로 변경하는 작업을 말한다. (ex) 문자열 '80' 을 숫자 80 으로 변환
- 데이터 타입 변환이 필요한 이유
    - **연산 성능 향상** -> 문자열을 숫자로 변환하면 수학 연산 속도가 증가한다.
    - **데이터 정확성 유지** -> 데이터가 올바른 타입으로 저장되어야 오류 방지가 가능하다.

### (1) CAST 함수
- `CAST` 함수는 데이터 타입을 변환하는 기본적인 방법이다.
- 'CAST' 함수는 다양한 데이터 타입 변환을 지원한다.
- `CAST( <source_data/column> AS <target_data_type>)`

(ex) 문자열을 정수로 변환
```SQL
SELECT CAST('80' AS INT);
```

(ex) 실수(FLOAT)를 정수로 변환
```SQL
SELECT CAST(99.99 AS INT);
```

(ex) 문자열을 날짜로 변환
```SQL
SELECT CAST('2024-02-10' AS DATE);
```

### (2) 더블 콜론(::) 연산자를 활용한 변환
- `CAST` 의 간결한 표현 방식으로, PostgreSQL 과 동일한 문법을 사용할 수 있다.
- **'CAST' 보다 간결한 문법을 원하면, 더블 콜론(::) 연산자를 사용** 하면 된다.
- `<source_data/column>::<target_data_type>)`

(ex) 문자열을 정수로 변환
```SQL
SELECT '80'::INT;
```

(ex) 문자열을 날짜로 변환
```SQL
SELECT '2024-02-10'::DATE;
```

(ex) 날짜를 TIMESTAMP로 변환
```SQL
SELECT '2024-02-10'::TIMESTAMP;
```
- 이 예시에서는 반환된 후, 원본 데이터에는 시간 세부 정보가 지정되어 있지 않으므로, 시간은 기본적으로 "00:00:00" 으로 설정된다.

### (3) TO_함수를 활용한 변환
- Snowflake 에서 제공하는 변환 함수이다.
- **TO_함수** 를 활용하면 특정 변환을 더 직관적으로 수행할 수 있다.

(ex) 숫자를 문자열로 변환(TO_VARCHAR)
```SQL
SELECT TO_VARCHAR(12345);
```

(ex) 문자열을 날짜로 변환(TO_DATE)
```SQL
SELECT TO_DATE('2024-02-10 14:30:00');
```
- Result : `2024-02-10`

(ex) 문자열을 TIMESTAMP 로 변환(TO_TIMESTAMP)
```SQL
SELECT TO_TIMESTAMP('2024-02-10 14:30:00');
```

### Snowflake 에서는 WHERE 절에서 alias 가 동작하는 이유가 뭘까?
- 기본적으로 쿼리 순서는 `FROM-WHERE-GROUP BY-HAVING-SELECT-ORDER BY` 인데, PostgreSQL 에서는 `SELECT` 절에 사용한 alias를 `WHERE` 절에서 사용할 수 없다.
- 하지만, **Snowflake 에서는 `SELECT` 절에서 만든 별칭(alias)을 `WHERE` 절에서 사용하도록 최적화** 할 수 있다.

(ex) 여기서 `WHERE` 조건에서 `request_date` 랑 `drop_time` 과 같이 alias 별칭을 사용해 쿼리를 작성했는데, `SELECT` 절은 마지막에 수행되는걸로 알고 있는데, TO_DATE(request_timestamp) > '2016-06-01' AND drop_timestamp::TIME < '6:00:00' 로 되어야만 하는거 아닌가? **왜 alias 를 사용해도 잘 동작하는건지 설명해줄래?**
```SQL
-- Convert request_id to VARCHAR using CAST method and alias to request_id_string
SELECT CAST(request_id AS VARCHAR) AS request_id_string,

-- Convert request_timestamp to DATE using TO_DATE and alias as request_date
	TO_DATE(request_timestamp) AS request_date,

-- Convert drop_timestamp column to TIME using :: operator and alias to drop_time
       drop_timestamp::TIME AS drop_time

FROM uber_request_data
-- Filter the records where request_date is greater than '2016-06-01' and drop_time is less than 6 AM.

WHERE request_date > '2016-06-01' -- 이 파트가 궁금!
       AND drop_time < '6:00:00' -- 이 파트가 궁금!
```

### (1) Snowflake 의 쿼리 최적화 엔진

- Snowflake는 **쿼리 재작성(Query Rewriting)** 최적화를 수행해서 실행 계획을 자동으로 조정한다.
- `SELECT` 절에서 별칭을 만들었더라도, Snowflake의 엔진은 이를 분석하고 **해당 변환을 미리 적용한 상태** 에서 `WHERE` 절을 실행하도록 최적화할 수 있다.
- 따라서, `WHERE` 절에서 `request_date` 와 `drop_time` 을 사용할 수 있는 것이다.

### (2) Snowflake 의 내부 실행 방식

- Snowflake는 쿼리를 실행하기 전에 내부적으로 **논리적 실행 계획** 을 구성하는데, 이 과정에서 `SELECT` 절에서 변환된 컬럼(`CAST` 나 `TO_DATE` 를 적용한 컬럼)을 미리 처리할 수 있다.
- Snowflake는 **공통 서브쿼리 제거(Common Subexpression Elimination, CSE)** 최적화 기법 덕분에 동일한 변환을 여러 번 수행하지 않도록 자동으로 처리된다.
- 따라서, 내부적으로 `TO_DATE(request_timestamp)` **변환을 미리 적용** 한 후, `WHERE` 절에서 이 값을 사용하도록 최적화 된 것이다.

### 정리
- 다른 SQL 엔진에서는 변환식을 직접 사용하거나 서브쿼리를 활용해야 하는데, Snowflake 에서는 내부적으로 쿼리를 최적화하여 `SELECT` 절에서 생성된 별칭을 `WHERE` 절에서도 사용할 수 있다. 즉, Snowflake의 내부 최적화 기능 덕분에 가능하지만, 범용적인 SQL을 고려하면 변환식을 직접 사용하는 것이 안전한 방법일 수는 있다!

<hr>


## Snowflake 의 함수, 정렬(Sorting) 및 그룹화(Grouping) 정리

## 1. Snowflake의 주요 함수(Functions)

### (1) 집계 함수(Aggregate Functions)
- Snowflake 의 집계 함수는 PostgreSQL 과 유사하게 동작한다.
- **테이블의 여러 행(row)에 대해 연산을 수행** 하는 함수이다.

(ex) 주문 테이블에서 평균, 합계, 최소, 최대 주문 금액 구하기
```SQL
SELECT 
    AVG(order_amount) AS avg_amount,
    SUM(order_amount) AS total_amount,
    MIN(order_amount) AS min_amount,
    MAX(order_amount) AS max_amount,
    COUNT(*) AS total_orders
FROM orders;
```

### (2) 문자열 함수(String Functions)
- 문자열을 조작할 때 사용한다.
- PostgreSQL 과 동일하게 사용가능하며, Snowflake 에서도 동일한 방식으로 활용 가능하다.

(ex) CONCAT - 문자열 연결
```SQL
SELECT CONCAT(category, ' - Pizza') AS pizza_category
FROM pizza_type;
```

(ex) UPPER & LOWER - 대소문자 변환
```SQL
SELECT
    UPPER(category) AS upper_category,
    LOWER(category) AS lower_category
FROM pizza_type;
```

### (3) 날짜 및 시간 함수(Date & Time Functions)
- 날짜 및 시간 데이터를 효율적으로 다룰 수 있는 유용한 함수들이다.

(ex) CURRENT_DATE - 현재 날짜 반환
```SQL
SELECT CURRENT_DATE;
```

(ex) CURRENT_TIME - 현재 시간 반환
```SQL
SELECT CURRENT_TIME;
```

(ex) EXTRACT - 날짜 및 시간에서 특정 부분 추출
- `EXTRACT ( <date_or_time_part> FROM <date_or_time_expr> )`
    - <date_or_time_part> 부분에는 `year`, `month`, `day` 등 날짜나 시간의 어느 부분을 원하는지 지정하는 곳이다.


```SQL
SELECT
    drop_timestamp,
    EXTRACT(YEAR FROM drop_timestamp) AS drop_year
FROM uber_request_data;
```

## 2. 정렬(Sorting) 과 그룹화(Grouping)

### (1) ORDER BY - 정렬
- PostgreSQL 과 동일한 `ORDER BY` 를 사용할 수 있다.

(ex) 주문 금액 기준으로 내림차순 정렬
```SQL
SELECT order_id, customer_id, order_amount
FROM orders
ORDER BY order_amount DESC;
```

(ex) 주문 날짜 기준으로 오름차순 정렬
```SQL
SELECT order_id, customer_id, order_date
FROM orders
ORDER BY order_date ASC;
```

### (2) GROUP BY - 그룹화
- PostgreSQL 과 동일하게 사용 가능하며, **집계함수와 함께 활용** 이 가능하다.
- 특정 컬럼을 기준으로 그룹화하여 집계 연산을 수행한다.

(ex) 고객별 총 주문 금액을 구하기
```SQL
SELECT customer_id, SUM(order_amount) AS total_spent
FROM orders
GROUP BY customer_id;
```

(ex) 피자 크기(size)별 평균 가격 구하기
```SQL
SELECT size, AVG(price) AS avg_price
FROM pizza_sales
GROUP BY size;
```

### (3) GROUP BY ALL - Snowflake의 고유한 기능
- 일반적으로 여러 개의 컬럼을 `GROUP BY` 할 때, 명시적으로 모든 컬럼을 나열해야 한다.
- 하지만, Snowflake 의 `GROUP BY ALL` 은 `SELECT` 절의 **모든 컬럼을 자동으로 그룹화** 한다.
- 즉, 모든 `SELECT` 절에 포함된 컬럼을 자동으로 `GROUP BY` 해주므로 편리하다!

(ex) 기존 방식 : `GROUP BY` 에 모든 컬럼 나열
```SQL
SELECT pizza_type_id, size, AVG(size) AS avg_price
FROM pizza_sales
GROUP BY pizza_type_id, size;
```

(ex) GROUP BY ALL 사용 시
```SQL
SELECT pizza_type_id, size, AVG(price) AS avg_price
FROM pizza_sales
GROUP BY ALL;
```

<hr>

## Snowflake의 JOIN 
- Snowflake에서 제공하는 Join 기능 중, 특히 Natural Join 과 Lateral Join 에 대해서 알아보자.

## 1. Snoflake 에서의 JOIN 개요
- SQL JOIN 은 여러 개의 테이블에서 데이터를 결합할 때 사용된다.
- Snowflake는 PostgreSQL 과 유사한 JOIN 기능을 제공한다.
- INNER JOIN, LEFT JOIN, RIGHT JOIN, FULL OUTER JOIN 등이 기본적으로 지원된다.

(ex) INNER JOIN 기본 예제
```SQL
SELECT p.pizza_id, p.size, p.price, pt.name, pt.category, pt.ingredients
FROM pizzas p
INNER JOIN pizza_type pt
ON p.pizza_type_id = pt.pizza_type_id;
```

## 2. Natural JOIN - 자동으로 같은 컬럼 매칭
- Natural JOIN 은 **동일한 컬럼명을 가진 컬럼을 자동으로 매칭하여 중복을 제거** 한다.
- `OUTER JOIN` 과 함께 사용할 수도 있다. -> Nautral [{LEFT, RIGHT, FULL} OUTER] JOIN
- `ON` 절을 사용하지 않고도 동일한 컬럼을 기준으로 JOIN 을 수행한다. -> `ON` 조건을 지정하려고 하면 구문 오류가 발생한다.
- 히지만, NATURAL JOIN 에서는 WHERE 절을 함께 사용할 수 있다. -> `WHERE`

(ex) NATURAL JOIN 기본 예제
```SQL
SELECT *
FROM pizzas
NATURAL JOIN pizza_type;
```
- 예를 들어, `pizza_type_id` 가 두 테이블에 존재하면 자동으로 이를 기준으로 JOIN 된다.

(ex) WHERE 절을 활용하면 특정 조건을 추가로 적용할 수 있다.
```SQL
SELECT *
FROM pizzas
NATURAL JOIN pizza_type
WHERE pizza_type_id = 'CLASSIC';
```

### (1) NATURAL JOIN 의 장점
- 중복 컬럼 제거 -> `pizza_type_id` 같은 컬럼이 중복될 경우 하나만 남긴다.
- 자동 매칭 -> 같은 이름을 가진 컬럼을 자동으로 찾아 JOIN 이 수행된다.
- 코드 단순화 -> `ON` 과 같은 조건을 생략할 수 있어 코드가 간편해진다.

### (2) NATURAL JOIN 의 주의점
- 동일한 컬럼명이 없으면 JOIN 이 불가능하다.
- 잘못된 매칭이 발생할 가능성이 있다. (ex. 동일한 이름이지만, 의미가 다른 컬럼이 있는 경우)

## 3. LATERAL JOIN - 동적 서브쿼리 활용
- LATERAL JOIN 은 **FROM 절의 서브쿼리에서** **이전 테이블의 컬럼이나 뷰를 참조** 할 수 있도록 지원한다.
- 일반적인 JOIN 보다 더 **동적으로 데이터를 결합** 할 수 있다.
- **JOIN이 불가능한 경우에도 LATERAL 을 활용하여 데이터를 매칭** 할 수 있다.
- 데이터를 정규화하여 분석 및 쿼리에 쉽게 사용할 수 있도록 도와주는 `FLATTEN` 함수도 있다.(`JSON` , `ARRAY` 같은 반정형(semi-structured) 데이터에서 개별 값을 추출하여 테이블 형태로 변환하는 기능을 수행하는 함수)

(ex) LATERAL JOIN을 사용하면 서브쿼리가 FROM 절에서 동적으로 실행된다! 
```SQL
SELECT p.pizza_id, lat.name, lat.category
FROM pizzas p,
LATERAL (
	SELECT *
	FROM pizza_type t
	WHERE p.pizza_type_id = t.pizza_type_id
) lat;
```
- **pizza p 를 LATERAL JOIN 내의 서브쿼리에서 참조** 했다.
- `JOIN` 키워드 대신 `WHERE` 키워드를 사용하면서 유사한 작업을 수행했다. -> 서브쿼리 내에 있는 쿼리가 복잡하고, 상위 테이블에 의존하고 있다면, 하위서브쿼리가 이런 복잡한 작업을 더 유연하게 수행할 수 있다.

(ex) Flatten function
```SQL
SELECT *
FROM TABLE(FLATTEN(input => <반정형 데이터 컬럼>));
```
- `FLATTEN(input => <반정형 데이터 컬럼>)` -> JSON 또는 ARRAY 데이터를 행으로 변환
- `TABLE(FLATTEN(...))` -> Snowflake 의 테이블 함수이므로 FROM 절에서 사용해야 한다.
- **FLATTEN()은 단독으로 사용할 수 없고, LATERAL JOIN 과 함께 사용** 해야 한다.

(ex) JSON 데이터에서 FLATTEN() 사용예제
```SQL
-- JSON 데이터 테이블 생성
CREATE TABLE orders (
    order_id INT,
    order_details VARIANT
);

INSERT INTO orders VALUES 
(1, '[{"item": "Pizza", "price": 10}, {"item": "Burger", "price": 8}]'),
(2, '[{"item": "Pasta", "price": 12}, {"item": "Salad", "price": 6}]');

-- JSON 배열을 FLATTEN()으로 테이블화
SELECT order_id, value:item::STRING AS item, value:price::INT AS price
FROM orders, LATERAL FLATTEN(input => order_details);
```

(ex) Array 데이터에서 FLATTEN() 사용예제
```SQL
-- ARRAY 데이터 테이블 생성
CREATE TABLE customers (
    customer_id INT,
    phone_numbers ARRAY
);

INSERT INTO customers VALUES 
(1, ARRAY_CONSTRUCT('010-1234-5678', '010-5678-1234')),
(2, ARRAY_CONSTRUCT('010-9999-8888'));


-- ARRAY 데이터에서 FLATTEN()으로 테이블화
SELECT customer_id, value AS phone_number
FROM customers, LATERAL FLATTEN(input => phone_numbers);
```

### (1) LATERAL JOIN vs 일반 JOIN 의 차이점

(ex) LATERAL JOIN 을 활용하면 **동적으로 데이터를 검색** 할 수 있다. -> multiple JOIN 으로도 동일한 결과를 얻을 수 있지만, 대용량 데이터 세트라면 훨씬 효율적일 수 있다.
```SQL
SELECT o.order_id, o.customer_id, total_price
FROM orders o,
LATERAL (
    SELECT SUM(p.price * od.quantity) AS total_price
    FROM order_details od
    JOIN pizzas p
	ON od.pizza_id = p.pizza_id
    WHERE od.order_id = o.order_id
) AS t;
```
- 각 주문(order_id)에 대해 주문상세(order_details) 의 가격 합계를 계산한다!

### (2) LATERAL JOIN 의 장점
- JOIN 으로 해결하기 어려운 경우 활용할 수 있다.
- 각 행(row)별로 서브쿼리를 실행할 수 있어 더 동적인 데이터 처리가 가능하다.
- 복잡한 쿼리를 단순화하고, 불필요한 데이터 처리를 줄여 성능 최적화를 할 수 있다.

<hr>

## Snowflake 의 서브쿼리(Subquery)와 공통 테이블 표현식(CTE) 정리
- 서브쿼리 개념 및 Correlated / Uncorrelated Subquery의 차이점
- Snowflake에서 LIMIT 과 서브쿼리의 사용제한 사항
- 공통테이블 표현식(CTE)을 활용한 가독성 높은 쿼리 작성법

## 서브쿼리(Subquery) 개요
- **서브쿼리는 다른 SQL 문 내에서 중첩된 SQL 쿼리** 를 말한다.
- **데이터 필터링, 집계, 연산을 수행**하는 데 활용한다.
- 주로 `FROM`, `WHERE`, `HAVING`, `SELECT` 절에서 사용 가능하다.

(ex) 기본적인 서브쿼리 예제 - 주문 금액이 평균 금액보다 큰 주문만 조회
```SQL
SELECT *
FROM orders
WHERE order_amount > (SELECT AVG(order_amount) FROM orders);
```

## 1.Correlated Subquery(상관 서브쿼리)
- **외부 쿼리(메인 쿼리)의 컬럼**을 **내부 서브쿼리에서 참조**하는 서브쿼리
- **각 행(row)마다 서브쿼리를 실행** 하여 데이터를 필터링한다.

(ex) Correlated Subquery 예제 - 각 피자 카테고리별 최고가 피자보다 저렴한 피자 조회
```SQL
SELECT p.pizza_id, p.size, p.price
FROM pizzas p
WHERE p.price < (
    SELECT MAX(price)
    FROM pizzas p2
    WHERE p2.pizza_type_id = p.pizza_type_id
);
```

### Correlated Subquery 의 한계 - LIMIT 사용 불가
- Snowflake는 **상관 서브쿼리 내부에서 `LIMIT` 를 사용할 수 없다!**

(ex) 오류 발생 예제
```SQL
SELECT p.pizza_id, p.size, p.price
FROM pizzas p
WHERE p.price < (
    SELECT MAX(price)
    FROM pizzas p2
    WHERE p2.pizza_type_id = p.pizza_type_id
    LIMIT 1  -- ❌ 오류 발생
);
```
- 대신, **CTE(Common Table Expression) 또는 JOIN 을 사용하여 해결** 할 수 있다.


## 2. Uncorrelated Subquery(비상관 서브쿼리)
- **외부 쿼리(메인 쿼리)와 독립적으로 실행** 되는 서브쿼리
- 메인 쿼리와 상관없이 **단독 실행이 가능** 하다.

(ex) Uncorrelated Subquery 예제 - 가장 비싼 피자를 주문한 내역 조회
```SQL
SELECT *
FROM orders
WHERE pizza_id = (
    SELECT pizza_id
    FROM pizzas
    ORDER BY price DESC
    LIMIT 1
);
```

- Uncorrelated Subquery(비상관 서브쿼리)는 `LIMIT` 를 사용할 수 있다.
(ex) Uncorrlated Subquery는 `LIMIT` 사용 가능
```SQL
SELECT pizza_id
FROM pizzas
ORDER BY price DESC
LIMIT 1;
```

## 3. 공통 테이블 표현식(CTE, Common Table Expressions)
- CTE 는 복잡한 서브쿼리를 쉽게 재사용하고 가독성을 높이는 방법이다.
- 쿼리를 작성하고 닉네임을 부여하는 것으로 이해하면 된다.
- **WITH 문을 사용** 하여 **쿼리 블록을 정의** 한 후, 이를 **메인 쿼리에서 활용** 한다.
- **JOIN 을 활용하면 더 효과적인 데이터 처리가 가능** 하다.

(ex) 기본적인 CTE 문법
```
WITH cte_name AS (
    SELECT column1, column2
    FROM table_name
    WHERE condition
)
SELECT *
FROM cte_name;
```

(ex) CTE 를 활용하여 동일한 결과를 조회한다. - 상반 서브쿼리를 사용하면 Snowflake에서 `LIMIT`를 사용할 수 없다.
```SQL
SELECT p.pizza_id, p.size, p.price
FROM pizzas p
WHERE p.price < (
    SELECT MAX(price)
    FROM pizzas p2
    WHERE p2.pizza_type_id = p.pizza_type_id
);
```
->
```SQL
WITH max_price AS (
    SELECT pizza_type_id, MAX(price) AS highest_price
    FROM pizzas
    GROUP BY pizza_type_id
)
SELECT p.pizza_id, p.size, p.price
FROM pizzas p
JOIN max_price mp -- Joining with CTE : max_price
ON p.pizza_type_id = mp.pizza_type_id
WHERE p.price < mp.highest_price;
```

- Snowflake는 **여러 개의 CTE를 동시에 정의할 수 있다.**
(ex) CTE 를 활용한 복수의 서브쿼리 결합 예시 - 상위 5명의 고객을 조회하고, 고객 정보를 결합하여 분석
```SQL
WITH cte_orders AS (
    SELECT order_id, customer_id, SUM(order_amount) AS total_spent
    FROM orders
    GROUP BY order_id, customer_id
),

cte_top_customers AS (
    SELECT customer_id, SUM(total_spent) AS total_spending
    FROM cte_orders
    GROUP BY customer_id
    ORDER BY total_spending DESC
    LIMIT 5
)

SELECT ctc.customer_id, ctc.total_spending, c.name
FROM cte_top_customer ctc
JOIN customer c ON ctc.customer_id = c.customer_id;
```

### CTE 사용의 장점
- 복잡한 서브쿼리를 분리하여 **가독성이 높다.**
- SQL을 모듈화하여 **유지보수 및 디버깅이 쉬워진다.**
- JOIN과 결합하여 **재사용성을 높이고 성능을 최적화할 수 있다.**
- 상관 서브쿼리에서 사용할 수 없는 `LIMIT` 등을 자유롭게 활용할 수 있다.

<hr>

## Snowflake 쿼리 최적화(Query Optimization)
- Snowflake 의 쿼리 최적화 개념 및 필요성
- **일반적인 비효율적인 쿼리 문제(Exploding Joins, SELECT, UNION 사용 문제 등)
- 효율적인 쿼리 작성법(WHERE 절 필터링, 조인 최적화, 불필요한 데이터 조회 방지 등)
- 쿼리 이력 조회(Query History)를 활용한 최적화 대상 파악 방법

## Snowflake 쿼리 최적화란
- 쿼리를 더 효율적인 형태로 변환하는 과정이다.
- **Snowflake의 Cloud Services Layer 가 자동으로 최적화하지만, 사용자 쿼리 작성 방식도 매우 중요** 하다.
- 잘 작성된 쿼리는 Snowflake 최적화를 더 효과적으로 활용하고, 실행 속도도 향상된다.

## 쿼리 최적화의 중요성
- **빠른 결과 처리** -> 속도가 중요한 데이터 분석 프로젝트에서 필수적이다.
- **비용 절감** -> Snowflake의 Virtual Warehouse 는 CPU, 메모리를 사용하며, 실행 시간이 길수록 크레딧 비용이 증가한다.
- **리소스 절약** -> 불필요한 연산을 줄이고, 최소한의 데이터만 처리하도록 유도한다.

## 일반적인 비효율적인 쿼리 문제 및 해결 방법

(ex) Exploding Joins(잘못된 조인으로 인한 데이터 폭발)

- 문제상황 : 모든 행이 모든 행과 매칭되면서 데이터가 기하급수적으로 증가 -> 매우 비효율적
```SQL
SELECT *
FROM order o
JOIN order_details od ON 1=1;  -- ❌  잘못된 조건 (Cartesian Product 발생)
```

- 해결 : **정확한 ON 조건을 사용하여 데이터 폭발 방지**
```SQL
SELECT *
FROM orders o
JOIN order_details od ON o.order_id = od.order_id; -- ✅ 정확한 조인 조건 사용
```

(ex) UNION vs UNION ALL

- 문제상황 : UNION 사용으로 인해 불필요한 중복 제거 작업 발생
```SQL
SELECT customer_id FROM orders
UNION  -- ❌ 
SELECT customer_id FROM order_details;
```

- 해결 : **중복이 없거나 신경 쓰지 않아도 확신한다면 UNION ALL 사용**
```SQL
SELECT customer_id FROM orders
UNION ALL -- ✅
SELECT customer_id FROM order_details;
```

(ex) SELECT * 사용 지양하기 : 데이터베이스는 불필요한 컬럼까지 가져오느라 연산량 증가 → 느려짐

- 문제상황 : 불필요한 모든 컬럼을 조회하면서 리소스 낭비
```SQL
SELECT * FROM orders;
```

- 해결 : **필요한 컬럼만 선택하여 조회**
```SQL
SELECT order_id, order_date FROM orders;
```

(ex) WHERE 절을 JOIN 전에 사용하기(Early Filtering)

- 문제상황 : JOIN 후 필터링을 하면 불필요한 데이터를 먼저 결합하면서 리소스 낭비
```SQL
SELECT *
FROM orders o
JOIN order_details od ON o.order_id = od.order_id
WHERE o.order_date > '2023-01-01'; -- ❌ 조인 후 필터링
```

- 해결 : **WHERE 절을 JOIN 전에 사용하기**
```SQL
WITH filtered_orders AS (
    SELECT * FROM orders WHERE order_date > '2023-01-01'
)
SELECT *
FROM filtered_orders o
JOIN order_details od ON o.order_id = od.order_id;
```

## Snowflake에서 쿼리 최적화하는 방법

### (1) TOP/LIMIT 사용하여 불필요한 데이터 조회 방지
- 불필요한 전체 데이터 조회 대신 제한된 결과만 반환한다 : `LIMIT` 을 사용하여 실행 시간을 단축하고 리소스를 절약
```SQL
SELECT * FROM orders ORDER BY order_date DESC LIMIT 10;
```

### (2) WHERE 절을 활용하여 필터링 강화
- JOIN 전에 필터링을 적용하여 처리할 데이터량을 줄인다. : 사전에 필터링하여 `JOIN` 및 `GROUP BY` 등의 연산 속도를 향상
```SQL
SELECT * FROM orders WHERE order_status = 'Delivered';
```

### (3) GROUP BY 최적화 : GROUP BY ALL 사용
- 모든 SELECT 컬럼을 기준으로 GROUP BY 할 때 유용하다. : `GROUP BY` 컬럼을 직접 나열하지 않아도 되므로 코드가 간결해진다.
```SQL
SELECT customer_id, order_status, COUNT(*) AS order_count
FROM orders
GROUP BY ALL; -- ✅ 모든 SELECT 컬럼을 자동으로 GROUP BY
```

## Query History를 활용한 쿼리 최적화
- 어떤 쿼리가 가장 오래 걸리는지 확인하는 방법이다.
```SQL
SELECT query_id, query_text,total_execution_time
FROM snowflake.account_usage.query_history
WHERE total_execution_time > 1000 -- 1초 이상 실행된 쿼리 필터링
ORDER BY total_execution_time DESC;
```
<hr>

##


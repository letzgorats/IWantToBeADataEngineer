## 데이터베이스 설계
- 데이터 베이스 설계는 비즈니스 요구를 충족시키기 위해 데이터를 구성하고 관리하는 과정을 말한다.
- 다양한 스키마, 관리 옵션, 데이터베이스 객체 등과 같은 요소를 고려해야 하며, 데이터 사용 방식에 따라 최적의 접근 방식이 달라진다.

## 데이터처리 접근법(OLTP vs OLAP)

### OLTP(OnLine Transaction Processing)
- 일상적인 트랜잭션과 운영에 초점을 맞춘다.
(ex) 서점에서 책 가격 추적, 직원 근무 시간 기록, 고객이 구매를 완료할 때 거래 기록
- 애플리케이션 지향적이다.
- 현재 데이터의 스냅샷 제공한다.
- 간단하고 빠른 쿼리와 업데이트 처리를 한다.
- 직원과 고객을 포함한 다양한 사용자가 활용한다.
- 비교적 적은 데이터

### OLAP(OnLine Analytical Processing)
- 장기적인 분석과 의사결정을 위한 설계이다.
(ex) 서점에서 가장 수익성이 높은 책 분석, 가장 충성도 높은 고객 파악, 직원 성과 분석
- 특정 분석 주제에 집중한다.
- 장기간 데이터를 통합하여 저장한다.
- 복잡한 쿼리 처리를 한다.
- 주로 데이터 분석가나 데이터 과학자가 활용한다.
- 대량의 데이터
![Image](https://github.com/user-attachments/assets/d0974d50-714d-4369-93de-2bdcd0085445)

### OLTP 와 OLAP 는 상호 보완적이다. 

(ex) OLTP 데이터를 OLAP로 보내는 상황 : OLTP 데이터는 운영 **데이터베이스** 에 저장되고, 이 데이터는 나중에 추출, 정제되어 OLAP **데이터 웨어하우스** 에 저장된다.

(ex) OLAP 인사이트를 OLTP로 보내는 상황 : OLAP 시스템에서 도출된 **분석 결과** 는 비즈니스 관행과 운영 의사결정에 영향을 미쳐 OLTP **데이터에 반영** 된다.


## 데이터 저장 방식

1) 구조화 데이터
    - 스키마에 의해 정의되고, 제약조건 등이 설정된다.
    - 데이터가 정리되고 조직화되어 있어서 분석에 용이하다.
    - 스키마를 따라야 하므로 유연성이 떨어지거나 확장성이 제한적일 수 있다.
    - (ex) 관계형 데이터베이스


2) 반구조화 데이터
    - 스키마를 따르지 않지만, 자체적으로 서술 가능한 구조를 가진다.
    - 구조화와 비구조화의 중간단계로 유연성과 구조의 장점을 지녔다.
    - (ex) NoSQL,XML,JSON


3) 비구조화 데이터
    - 스키마가 없으며, 정제되진 않은 원시적인 형태의 데이터이다.
    - 유연성과 확장성이 뛰어나지만, 데이터 분석이 까다롭고 처리시간이 더 걸릴 수 있다.
    - (ex) chat logs,photos,MP3,media files


## 데이터 저장 솔루션

1) 전통적인 데이터베이스(=일반적인 DB)
    - 관계형 스키마를 따르는 데이터베이스로 주로 OLTP에 사용된다.
    - 과거에는 데이터 저장이 충분했으나, 빅데이터와 데이터분석의 등장으로 한계가 발생했다.
    
2) 데이터 웨어하우스(DW)
    - 읽기 전용분석을 최적화하는데, 여러 소스의 데이터를 통합한다.(OLAP에 주로 사용된다.)
    - **소규모 데이터 분석** 에 용이하다.
    - 대규모 병렬처리를 통해 빠른 쿼리 수행이 가능하다.(Massively Parrel Processing=MPP)
    - (ex) Google BigQuery, Amazon Redshift, Microsoft Azure SQL Data Warehouse
    - 특정 주제에 집중한 데이터웨어하우스의 하위집한 '데이터마트'가 있다.(부서별 데이터 접근성을 향상시킨다.)
    
3) 데이터 레이크(DL)
    - 모든 유형의 데이터를 **저비용** 으로 저장하고, 스키마(데이터 구조)가 쓰기 시점이 아닌 **읽기 시점** 에 정의된다.(schema-on-read)
    - 대량의 비구조화 데이터를 저장 가능하다.(보통 PB=1000TB 사이즈다!)
    - 딥러닝, 데이터 발견 등 **대규모 데이터 분석** 에 용이하다.(Apache Spark 나 Hadoop 과 같은 서비스를 사용한다.)
    - 관리와 카탈로그화가 부족하면 '데이터늪(data swamp)'에 빠질 수도 있다.
    - (ex) Amazon S3, Google Cloud Storage, Mircrosoft Data Lake


## ETL vs ELT
- ETL 은 말그대로 추출,변환,적재 순이니까, 데이터를 저장하기 전에 변환을 수행한다.(주로 데이터 웨어하우스 및 소규모 분석에 사용된다.)
- ELT 는 말그대로 추출,적재,변환 순이다. 즉, 원시형태로 데이터를 저장 후에, 필요에 따라서 변환한다.(데이터 레이크와 같은 빅데이터 프로젝트에서 사용된다.)
![Image](https://github.com/user-attachments/assets/70fbe85a-d3d3-4c03-8de9-ab318a0ca1fc)


## 데이터베이스 설계
- 데이터베이스 설계는 데이터가 논리적으로 저장되는 방식을 결정하는 과정이다. 이는 데이터베이스를 읽거나 업데이트하는 쿼리에 직접적인 영향을 미친다. 데이터베이스 설계에서 중요한 두 가지 개념은 **데이베이스 모델링** 과 **스키마** 이다.

### 데이터베이스 모델 
- 데이터베이스 구조에 대한 고수준의 명세이다. 가장 인기있는 모델은 관계형 모델로, 행(row)을 레코드로, 열(coulmn)을 속성으로 정의한다. 각 행은 고유 키를 가져야 한다는 규칙이 있다. (물론, 다른 모델은 이러한 규칙이 없을수도 있다.)
    - 1) 개념적 모델(Conceptual Model)
            - 데이터베이스가 포함하는 엔터티,관계,속성을 정의하며, 시스템의 전반적인 데이터를 추상적으로 설명한다.
    - 2) 논리적 모델(Logical Model)
            - 이러한 엔터티와 관계가 테이블에 어떻게 매핑되는지를 결정한다.(개념적 모델을 테이블,키,관계로 변환해 논리적 구조를 정의한다.)
            - (ex) 관계형 모델(realtional model) : 데이터를 테이블 형태로 구성하고, 테이블 간의 관계를 외래키와 같은 개념으로 정의한다.
    - 3) 물리적 모델(Physical Model)
            - 가장 낮은 수준의 추상화로 논리적 모델을 실제 저장소에 구현하는 방식을 정의한다.
            - (ex) MySQL, PostgreSQL 와 같은 특정 DBMS 에 맞는 테이블 생성 및 인덱스 설정


## 스키마
- 데이터베이스의 청사진이다. 
- 어떤 테이블, 필드, 관계, 인덱스, 뷰 등을 가질것인지 정의한다. 
- 관계형 데이베이스에 데이터를 삽입할 때는 이 스키마구조를 잘 준수해야 한다.


## 관계형 모델링을 넘어 **dimensional model(차원 모델링)**
- 데이터 웨어하우스를 위한 **차원 모델링(dimensional modeling)** 이 있다.
- 이는 **OLAP 쿼리에 최적화된 모델로, 분석을 목표** 로 한다.
- 이를 위해 **스타 스키마** 를 사용한다.
- 주로 두 가지 유형의 테이블로 구성되는데,

  1) Fact table(팩트 테이블)
      - 주요 메트릭을 기록하며, **자주 변경** 된다. 팩트 테이블은 차원 테이블의 외래 키를 포함한다.
  2) Dimensional table(차원 테이블)
      - 특정 속성에 대한 설명을 포함하며 **자주 변경되지 않는다.**
    


## 스타 스키마
- 차원 모델링 : 스타 스키마 (몇몇은 혼용해서 사용하기도 한다.)
- 2가지 테이블로 구성되어 있다.
    - 1) fact tables(팩트 테이블)
        - 주요 메트릭을 저장(ex.판매 금액과 수량)
    - 2) dimension tables(차원 테이블)
        - 팩트 테이블의 메트릭을 설명하는 추가 정보를 저장(ex.판매된 책의 세부 정보, 판매 시간, 책을 구매한 상점 정보)

- 테이블 간 **일대다 관계** 가 형성된다.(한 상점은 여러번의 판매에 포함될 수 있지만, 하나의 판매는 하나의 상점에만 속한다,)
- 테이블 간 연결이 별 모양처럼 보이기 때문에 **스타 스키마** 라고 한다.

## 스노우플레이크 스키마
- 스타 스키마의 확장 버전으로, 차원 테이블이 정규화되어 더 많은 테이블로 나뉜다.
- 팩트 테이블은 동일하지만, 차원 테이블이 더 세분화된 버전이다.

## 정규화
- 데이터를 중복을 줄이고 무결성을 높이기 위해 테이블을 더 작은 테이블로 나누는 기술이다.
- 반복되는 데이터 그룹을 식별하고 이를 새로운 테이블로 이동한다.
- 테이블 수가 많아 쿼리가 복잡하지만, 데이터 중복이 없어 저장 공간을 절약하고 데이터 무결성을 보장한다.
- (ex) 스노우플레이크 스키마에서는 8개의 테이블을 조인해야 하며, 때문에 쿼리가 더 복잡하고 느리다.
<-->
## 비정규화
- 데이터가 중복되어 테이블 수가 적고, 쿼리가 간단하며 읽기 속도가 빠르다.
- (ex) 스타 스키마에서는 3개의 테이블을 조인해 간단하게 쿼리가 가능하다. 

## 정규화의 이점
    
    - Enforcing data consistency
    - Safer updating, removing, and inserting   
    - Easier to redesign by extending

    - 1) 공간 절약 : 중복 데이터를 제거하여 저장 공간 효율을 높인다.
        - (ex) "Brooklyn"과 같은 데이터가 여러번 저장되는 대신 한 번만 저장한다.
    
    - 2) 데이터 무결성 : 데이터 일관성을 유지하고, 입력 오류를 줄인다.
        - (ex) "CA"와 "California"를 통일한다.
    
    - 3) 유지 관리 용이성 : 데이터 수정 시 더 간단하다.
        - (ex) state 이름을 변경할 때 단 한 곳에서 수정한다.
    
    - 4) 확장성 : 작은 테이블로 분리되어 데이터베이스 확장이 용이하다.

## 정규화의 단점
    - 1) 느린 읽기 속도 : 테이블 수가 많아져 조인 작업이 증가한다.
    
    - 2) 복잡성 증가 : 쿼리가 길고 복잡해져 사용하기 어려울 수도 있다.
    
## OLTP 와 OLAP 에서의 사용사례
- OLTP 에서는 쓰기작업이 많아 **정규화를 선호** 한다.
- 데이터의 일관성과 빠른 업데이트가 중요하기 때문이다.

- OLAP 에서는 읽기작업이 많아 **비정규화를 선호** 한다.
- 쿼리 속도와 분석 작업의 간소화가 중요하기 때문이다.



## 정규화(Normalization)

- Identify repeating groups of data and create new tables for them
    - The goals of normalization are to
        - be able to characterize the level of redundancy in a relational schema
        - provide mechanisms for transforming schemas in order to remove redundancy
- 데이터 중복을 줄이고 데이터 무결성을 보장하기 위해 데이터를 더 작은 테이블로 나누고 관계를 정의하는 과정이다.
- 이 과정은 데이터를 정리하고, 공간을 절약하며, 데이터베이스의 유지보수를 쉽게 만든다.

# 정규화 단계
- 1NF -> 2NF -> 3NF -> EKNF(Elementary key normal form) -> BCNF(Boyce-Codd normal form) -> 4NF -> ETNF(Essential tuple normal form) -> 5NF -> DKNF(domain-key normal form) -> 6NF

## 제 1정규형(1NF)
- **모든 레코드는 고유** 해야하며, **각 셀은 하나의 값만** 가져야 한다.
- (ex) 한 열에 여러 값이 포함되어 있다면, 이를 분리하여 각 값이 개별 셀에 있도록 수정한다.
- ![Image](https://github.com/user-attachments/assets/c399c5be-ffec-4e40-95ae-0c29644ea989)  ![Image](https://github.com/user-attachments/assets/cb6c0b1b-3ca6-440d-bfca-3513263b7f31)

## 제 2정규형(2NF)
- 1NF를 만족해야 하며, 이미 primary key가 하나의 열이라면, 자동적으로 2NF를 만족한다.
- 만약, 복합 primary키(복합 기본키 : 기본 키가 2개이상의 열로 구성되는 경우)라면, 키가 아닌 각 열은 모든 키에 종속되어야 한다.
- (ex) 복합키가 있을 경우, 키가 아닌 각 열(속성)이 해당 키 전체에 의존하지 않는다면 이를 분리한다.

- ![Image](https://github.com/user-attachments/assets/849fca4d-59c8-42a7-9dd8-7164b7f21454)
- student_id 와 course_id 가 둘 다 pk인 복합키 테이블이다. 2NF를 충족하는지 보려면, pk를 제외한 다른 열들이 이 2개의 열에 의존성을 가지는지 살펴봐야 한다.
- instructor_id 컬럼과 instructor 컬럼은 student_id 에는 의존하지 않지만, course_id 에는 의존한다.(course_id 에만 의존) 
- 반면, progress 는 student_id 과 course_id 둘다에 의존한다.(student_id 와 course_id 둘 다에 의존)

- 이를 고려해서 정규화를 하면 아래와 같다. 
- ![Image](https://github.com/user-attachments/assets/46976697-0042-4f61-82e6-2d1254d97982)
 
## 제 3정규형(3NF)
- 2NF를 만족해야 하며, 키가 아닌 열들이 다른 키가 아닌 열들에 의존하면 안된다.(=전이적 종속성을 허용하지 않는다.)
- 즉, **기본키가 아닌 열** 이 또다른 **기본키가 아닌 다른 열** 에 종속될 수 없다.
- (ex) 중간 속성에 의존하는 속성이 있다면, 이를 별도 테이블로 분리해야 한다.

- ![Image](https://github.com/user-attachments/assets/005224e0-201e-4045-a737-9f61b4466b8c)
- course_id 는 기본키이니까 여기선 잠깐 무시해도 된다. 다른 열을 살펴보면, instructor_id 컬럼과 instructor 컬럼은 확실히 서로 의존을 한다.
- tech 컬럼은 instructor에 의존하지는 않는다.(강사가 다양한 기술을 가르칠 수 있기 때문이다.)

- 이를 고려해서 아래와 같이 정규화를 할 수 있다.(아래 테이블은 복합 기본키도 없으므로 2NF도 충족하고, 전이적 종속성이 없어서 3NF도 충족한다.)
- ![Image](https://github.com/user-attachments/assets/a56a3080-9067-4d9a-a81d-164631fec188)


# 왜 우리는 이런 정규화를 거쳐야 할 필요가 있을까?

- 1NF 로만 충분하지 않은 이유가 뭘까? **충분하게 정규화되지 않은 데이터베이스는 업데이트, 삽입, 삭제 라는 3가지 유형의 이상 오류가 발생** 하기 쉽기 때문이다.


## 데이터 이상 현상

### 1) 갱신 이상(Update Anomaly)

- **중복된 데이터베이스를 업데이트할 때, 발생할 수 있는 데이터 불일치** 를 말한다.
- (ex) 학생 이메일을 변경할 때, 모든 레코드를 수정해야 한다.
- ![Image](https://github.com/user-attachments/assets/a635463c-6e24-4fc7-b5f9-e1b52b90d12c)
- 여러 레코드를 업데이트하는 것이 쉬워보일 수 있지만, 위험하다.
- 왜냐하면, 사용자가 이 중복성을 기억하는지 여부에 달려있고, 규모가 커질수록 이러한 중복성을 추적하기가 더 어려워진다.

### 2) 삽입 이상(Insertion Anomaly)
- **속성 누락으로 새 레코드를 추가할 수 없는 경우** 를 말한다.
- (ex) 학생이 과정을 수강하지 않으면, 데이터베이스에 추가할 수 없다.
- ![Image](https://github.com/user-attachments/assets/72644641-21c4-409d-a67d-e40812c99914)
- 유일한 예외는 enrolled_in 열이 null 을 허용할 수 있는 경우이다.
- 동일한 테이블에 있는 열 간의 종속성으로 인해, 테이블에 삽입할 수 있는 항목이 의도치 않게 제한될 수 있는 것이다.

### 3) 삭제 이상(Deletion Anomaly)
- **특정 데이터를 삭제하면 관련 데이터도 의도치 않게 삭제되는 경우** 를 말한다.
- (ex) 학생 데이터를 삭제하면, 해당 과정 정보도 손실될 수 있다.
- ![Image](https://github.com/user-attachments/assets/176cb993-1dd3-41c7-8d3a-5a0d4f8054d8)
- 이런 학생 중 하나를 삭제하면, 다른 열에 대한 정보도 손실될 수 있다. 이는 해당 정보를 다른 테이블에 넣으면 중복성 문제를 해결해서 삭제이상을 피하게 할 수 있다.(=정규화를 해야한다.)


# 데이터베이스를 더 정규화하면 할 수록, 이런 이상현상은 덜 발생한다. 하지만, 정규화의 단점도 있기에, 목적에 맞게 적절히 하는것이 중요하다.


## 정규화와 비정규화의 균형

- 정규화 : 쓰기 작업이 많은 OLTP 시스템에 적합하며, 데이터 무결성과 유지보수를 강화한다.(데이터의 일관성과 빠른 업데이트가 중요)
- 비정규화 : 읽기 작업이 많은 OLAP 시스템에 적합하며, 빠른 읽기 속도를 제공한다.(쿼리 속도와 분석 작업의 간소화가 중요)

<hr>

# 뷰
- 뷰는 물리적 **스키마에 포함되지 않은 가상 테이블** 이다.
- 물리적 메모리를 차지하지 않으며, 뷰를 생성하는 쿼리만 저장된다.
- 뷰의 데이터는 같은 데이터베이스의 테이블에서 가져온다.
- 뷰가 생성되면 일반 테이블처럼 쿼리할 수 있다.

## 뷰의 장점
- 자주 사용하는 쿼리를 반복해서 작성할 필요가 없다.(뷰를 생성한 후, 일반 테이블처럼 쿼리가 가능하다.)
- 데이터베이스 스키마를 변경하지 않고도 가상 테이블을 추가할 수 있다.

정리하면, 
- 저장 효율성 : 뷰는 쿼리문만 저장하므로 메모리를 거의 사용하지 않는다.
- 접근 제어 : 특정 사용자에게 민감한 정보를 숨기고 필요한 정보만 제공할 수 있다.
- 복잡성 단순화 : 겅규화된 스키마나 복잡한 조인을 감추고, 공통작업을 뷰로 생성하여 시간을 절약하고 사용성을 높일 수 있다.

## 뷰 생성 문법

    CREATE VIEW view_name AS
    SELECT column1,column2
    FROM table_name
    WHERE 조건;

- 이렇게 만든 뷰는 일반 테이블처럼 쿼리가 가능하다.(동작원리는 물론, 뷰에 정의된 원본쿼리를 실행한다.)

 
# 뷰 관리


## 뷰 보기

- 데이터베이스에 존재하는 모든 뷰를 확인하려면, **INFROMATION_SCHEMA.views** 테이블을 조회하면 된다.

- PostgreSQL 전용 명령
```
SELECT *
FROM INFROMATION_SCHEMA.views;
```
- 시스템 뷰를 제외하고 사용자 정의 뷰만 확인
```
SELECT table_name
FROM INFROMATION_SCHEMA.views
WHERE table_schema NOT IN ('pg_catalog','information_schema');
```

## 뷰에 대한 권한 부여 및 회수

- 권한(privilege) 부여(grant)
```
GRANT [권한] ON [객체] TO [역할]; 
```
(ex) ratings 객체에 대한 UPDATE 권한을 모든 사용자(PUBLIC)에게 부여한다.
```
GRANT UPDATE ON ratings TO PUBLIC;
```

- 권한(privilege) 회수(revoke)
```
REVOKE [권한] ON [객체] FROM [역할];
```
(ex) 특정 사용자(db_user)의 INSERT 권환 회수
```
REVOKE INSERT ON films FROM db_user
```

## 뷰 업데이트
- 뷰는 물리적 테이블이 아니지만, 특정 조건을 만족하는 경우에 업데이트가 가능하다.
    - 업데이트가 가능한 뷰의 조건
        - 1) **하나의 테이블로 구성** 되어야 한다.
        - 2) **집계 함수나 윈도우 함수에 의존하지 않아야 한다.** 

## 뷰에 데이터 삽입
- INSERT 명령어로 뷰에 데이터를 삽입하면 실제로는 뷰 뒤의 테이블에 삽입된다.
    - 삽입 가능한 뷰의 조건
        - 1) 업데이트 가능한 뷰의 조건과 유사하다.

### 일반적으로는 뷰를 통해 수정하지 않는게 좋다. 뷰는 읽기 전용 목적으로 사용하는 것으로 권장된다.

## 뷰 삭제
- **DROP VIEW** 명령어로 뷰를 삭제할 수 있다.
- 유용한 매개변수 : 
   - RESTRICT : 다른 객체가 해당 뷰에 의존하는 경우 오류를 반환한다.(기본값)
   - CASCADE : 뷰와 해당 뷰에 의존하는 모든 객체를 삭제한다.
   - (ex)
    ```
    DROP VIEW view_name CASCADE;
    ```
   - view_name에 해당하는 모든 객체를 삭제하는 것이다. 종속관계를 잘 파악해서 테이블을 적어야 한다.
   
## 뷰 재정의
- 뷰의 정의된 쿼리를 변경하려면 **CREATE OR REPLACE** 명령어를 사용해야 한다.
- (ex)
```
CREATE OR REPLACE VIEW view_name AS
SELECT new_column1, new_column2
FROM new_table;
```
- 단, **기존의 컬럼 이름,순서,데이터 타입** 은 동일해야 한다. 
- 새로운 컬럼만 추가한다면, 끝에 추가 가능하다.
- 뷰 재정의 조건을 못 맞춘다면, 기존 뷰를 삭제하고 새 뷰를 만들면서 해결할 수 있다.

## 뷰 속성 변경
- **ALTER VIEW** 명령어로 뷰의 속성을 변경할 수 있다.
- (ex) 이름, 소유자, 스키마 변경 등이 이에 해당한다.
```
ALTER VIEW view_name
RENAME TO new_view_name;
```

정리하자면, 
- 뷰는 데이터 접근 제어, 복잡한 쿼리 단순화, 읽기 전용 데이터 제공에 유용하다.
- 그러나, 데이터 수정보다는 읽기 전용 용도로 사용하는 것이 바람직하다.
- 뷰 관리에는 권한 설정, 삭제, 재정의, 속성 변경 등의 작업이 포함된다.

<hr>
- 뷰에는 사실 두 가지 유형이 있다.

## Non-Materialized Views(비물리화 뷰)
- 단순히 쿼리를 저장하고, 호출 시 쿼리를 실행하여 **가상 테이블** 을 생성한다.
- 여태까지 얘기한 뷰는 이에 해당한다.

## Materialized Views(물리화 뷰)
- 쿼리 결과를 **물리적으로 저장** 한다.(이름처럼!)
- 호출 시 쿼리를 실행하지 않고, 디스크에 저장된 쿼리 결과를 반환한다.(빠르게 응답이 가능하다.)
- 뷰를 갱신(Refresh)해야 최신 데이터를 반영할 수 있다.
- 갱신 주기는 주기적으로 스케줄링을 통해서 하는데, 보통 매일 야간 혹은 매시간 주기로 한다.
- 스케줄링 도구(cron jobs)를 사용해 자동갱신 설정이 가능하다.(PostgreSQL에는 뷰 갱신을 자동화하는 명령이 없다. cron jobs와 같은 도구(unix 기반의 작업 스케줄러)를 사용해서 갱신자동화를 수행할 수 있다.)
- 보통 데이터웨어하우스에서 유용하다.(데이터 웨어하우스는 주로 데이터 쓰기작업보다 분석에 더 많은 것을 의미하는 OLAP에 사용되기 때문이다.) 
- 복잡한 쿼리 결과를 미리 계산하고 저장함으로써, 동일한 쿼리가 반복적으로 실행되는 환경인 데이터 웨어하우스에서 성능을 크게 개선할 수 있다 -> 이에 대한 쿼리 계산 비용인 추가적인 비용도 든다.)
- 데이터 웨어하우스는 대규모 데이터를 처리하기 위해 고성능 컴퓨팅 리소스를 사용하므로 비용이 높은데, 물리화 뷰는 실행시간을 조금이라도 줄여 효율성을 높이지만, 데이터 웨어하우스 자체의 리소스 요구량 때문에 운영비용 절감에는 한계가 있다.
 
## 물리화 뷰의 장점
- 실행시간이 긴 쿼리의 결과를 빠르게 제공한다.
- 데이터 분석에서 효율적이다.

## 물리화 뷰의 단점
- 뷰의 데이터는 마지막 갱신 시점까지만 최신 상태이다.
- 자주 업데이트되는 데이터에는 부적합하다.

## 물리화 뷰 생성 문법
```
CREATE MATERIALIZED VIEW view_name AS
SELECT column1, column2
FROM table_name
WHERE condition;
```

## 물리화 뷰 갱신 문법
```
REFRESH MATERIALIZED VIEW view_name;
```


## 의존성 관리
- 의존성 관계
    - 뷰가 다른 뷰를 참조하는 경우, 갱신 순서를 관리해야 한다.
    - (ex) 두 개의 물리화 뷰 X와 Y에서 Y는 X를 참조할 때(X->Y), X가 Y보다 더 긴 실행시간을 가질 경우, Y가 X 갱신 전에 먼저 갱신완료되면, 오래된 데이터를 포함하게 된다.
    - 즉, 이런 종속성 체인(dependancy chain)이 생기는 경우를 예방하기 위해 모든 뷰를 동시에 갱신하는 것보다, 의존성을 체계적으로 관리해야 한다.

    - 의존성 관리 도구를 활용하면 된다.
        - DAG(Directed Acyclic Graphs,방향 비순환 그래프) : 각 노드는 뷰를, 화살표는 의존성을 나타낸다.(유한하다.)
        - 순환이 없어야 한다.(뷰가 다른 뷰를 의존하고, 다시 스스로를 참조할 수 없게 해야한다.즉, 오직 하나의 뷰만 다른 뷰에 의존하도록 방향성이 있어야 한다.)
        - 그럼 무슨 도구가 있나?
            - Airflow, Luigi 와 같은 파이프라인 스케줄링 도구를 사용해야 한다는 것이다.
            - DAG를 활용해 의존성 순서에 따라 갱신 작업을 자동화하는 것이 중요하다.

![Image](https://github.com/user-attachments/assets/d5a61460-7c76-4dda-b31e-bb0fc918a7b5)


<hr>

## Database roles
- **Roles(역할)** 은 데이터베이스 접근 권한을 관리하기 위해 사용되는 개체이다.
- 데이터베이스 접근 권한을 효율적으로 관리하기 위한 중요한 도구라고 생각하면 된다.
- 역할의 두 가지 주요 기능 
    1) 권한 정의 : 로그인, 데이터베이스 생성, 테이블 접근 등 역할이 수행할 수 있는 작업
    2) 클라이언트 인증 : 역할의 비밀번호, 유효기간 등 사용자 인증과 관련된 속성

- Role은 여러 사용자에게 할당이 가능하다.
- 글로벌한 특징이 있다.(이는 클러스터 내의 모든 데이터베이스에서 참조가 가능하다는 말이다.)


### Role 생성
- 기본적으로 생성시에는 아무런 권한도 할당되지 않는다.
- **CREATE ROLE** 명령으로 역할을 생성한다.
- (ex) data_analyst 역할 생성
```
CREATE ROLE data_analyst;
```
- (ex) 속성 설정과 함께 권한 부여 - 비밀번호 및 유효 기간 설정
```
CREATE ROLE intern WITH PASSWORD 'PasswordForIntern' VALID UNTIL '2025-01-01';
```
- (ex) 속성 설정과 함께 권한 부여 - 데이터베이스 생성 권한 부여
```
CREATE ROLE admin WITH CREATEDB;
```
- **ALTER ROLE** 명령으로 기존 역할을 수정할 수 있다.
- (ex) 역할 수정 - 관리자 역할도 역할을 생성할 수 있도록 허용
```
ALTER ROLE admin WITH CREATEROLE;
```
- (ex) 역할 수정 - owen 에게 비밀번호 부여
```
ALTER ROLE owen WITH PASSWROD '123124';
```

### 권한 부여 및 회수
- GRANT 와 REVOKE 를 사용하여 역할에 권한을 부여하거나 제거한다.
- (ex) ratings 테이블에 UPDATE 권한을 부여한다.
```
GRANT UPDATE ON ratings TO data_analyst;
```
- (ex) data_analyst 역할에서 UPDATE 권한 회수
```
REVOKE UPDATE ON ratings FROM data_analyst;
```
- PostgreSQL에서 사용가능한 권한은 아래와 같다.
    - ```SELECT, INSERT, UPDATE, DELETE, TRUNCATE, REFERENCES, TRIGGER, CREATE, CONNECT, TEMPORARY, EXECUTE, USAGE ```

## Users 와 Groups 관계
- Role은 사용자 역할(user role) 과 그룹역할(group role) 로 나뉠 수 있다. 
    - 사용자 역할 : 한 명의 특정 사용자를 위한 역할이다.
    - 그룹 역할 : 여러 사용자가 공유하는 역할로, 다른 역할을 멤버로 가질 수 있다.

- PostgreSQL 에서 사용자는 운영체제 사용자와는 완전히 독립적이며, 데이터베이스의 논리적 개념이다.
    - (ex) data_analyst 을 그룹 역할로 사용하고, intern 을 사용자 역할로 사용한다.
    - 그룹역할 생성
    ```
    CREATE ROLE data_analyst;
    ```
    - 사용자 역할 생성
    ```
    CREATE ROLE intern WITH PASSWORD 'PasswordForIntern' VALID UNTIL '2020-01-01';
    ```

- PostrgreSQL에서는 역할 간 계층 구조를 생성할 수 있다.
    - (ex) owen 을 data_analyst 그룹에 추가할 수 있다.
    ```
    GRANT data_analyst TO owen;
    ```
     - (ex) owen 을 data_analyst 그룹에서 제거할 수 있다.
    ```
    REVOKE data_analyst FROM owen;
    ```

- PostgreSQL 에는 일반적으로 사전 정의된 기본 역할세트가 존재하며, 이는 특별한 권한과 정보를 제공한다.
    (ex) pg_read_all_things, pg_read_all_stats, pg_signal_backend, More,... 
 
    
## ROLES 의 장점과 주의점
- 장점
    1) 역할은 직원 계정 생성 전에도 미리 정의가 가능하다.
    2) 공통 권한을 그룹화하여 데이터베이스 관리자(DBA)의 시간을 절약해준다.
- 주의점
    1) 역할이 과도한 권한을 부여할 경우, 데이터 보안 문제가 발생할 수 있다.
    2) 역할과 권한을 신중하게 관리해야 한다.


<hr>

## 테이블 파티셔닝(table partitioning)

- 파티셔닝은 큰 테이블을 여러 작은 부분으로 나누는 작업이다.
- 테이블 크기가 너무 커지면(수백GB 또는 TB 규모) 쿼리 성능이 저하될 수 있다.
- 이런 인덱스가 너무 커져서 메모리에 적재되지 않을 수 있는 상황을 파티셔닝을 통해 데이터를 나누어서 쿼리 성능을 최적화하는 것이 목적이다.


## 데이터 모델링 관점에서의 파티셔닝
- 물리적 데이터 모델의 일부
    - 논리적으로는 **동일한 데이터** 로 간주한다.
    - 데이터를 **여러 물리적 엔터티(테이블)로 분산** 하여 관리하다.
    - 정규화는 아예 논리적 데이터 모델을 바꾸는데, 파티셔닝은 논리적 데이터 모델은 그대로고 물리적으로 테이블을 바꾸는 것이다.
    
## 파티셔닝 유형

1) 수직 파티셔닝(Vertical Partitioning)
    - 테이블을 열(column) 기준으로 분리한다.
    - 완전히 정규화된 테이블이라도 특정 열을 분리하여 별도의 테이블로 저장한다.
    - (ex) 제품 데이터 테이블(4개 열)을 수직 파티셔닝 한다면,
        - 첫 3개의 열을 테이블 1에 저장한다.
        - 마지막 열(잘 사용되지 않는 긴 설명)을 테이블 2로 분리한다.
        - 두 테이블은 **공유키** 로 연결한다.
    - 드물게 조회되는 데이터는 느린 저장 매체에 저장하여 주요 쿼리 성능을 개선한다.
    - (이렇게 하면, 검색쿼리에서 스캔해야 하는 데이터가 줄어들기 때문에 첫 번째 테이블에 대한 쿼리 시간이 향상된다.)
![Image](https://github.com/user-attachments/assets/0b3de32d-435b-4ad1-8c5d-00a85c763746)

2) 수평 파티셔닝(Horizontal Partitioning)
    - 테이블을 행(row) 기준으로 분리한다.
    - (ex) 책 판매 데이터 테이블을 연도별로 분리한다.
    - (ex) 추가적으로 분기별로 더 세분화가 가능하다.

        ![Image](https://github.com/user-attachments/assets/d811095d-a579-4d74-b024-0fa55bfc3644)


## 수평 파티셔닝 구현 방법
- SQL 툴마다 살짝씩 다른데, PostgreSQL 10 부터는 선언적 파티셔닝(declartive partitioning)을 지원한다.

- 테이블 생성 시,  끝에 PARTITION BY RANGE 혹은 PARTITION BY LIST 를 사용하고 분할 기준으로 사용할 열을 (괄호)안에 넣어준다.
- 범위는 RANGE, 리스트는 LIST 라고 써주면 된다.
```
CREATE TABLE sales (
    id SERIAL,
    sale_date DATE,
    amount NUMERIC
) PARTITION BY RANGE (sale_date);
```
```
CREATE TABLE film_partitioned (
  film_id INT,
  title TEXT NOT NULL,
  release_year TEXT
)
PARTITION BY LIST (release_year);
```

- 그 다음에, 기준에 맞게 특정 파티션을 생성하면 된다. 
- 이 때는 파티션테이블 이름을 정하고 **PARTITION OF** 뒤에 해당 테이블을 써주면 된다.
- FOR VALUES FROM () TO () 를 사용해서 특정 범위를 정해주면 된다.(RANGE)
- FOR VALUES IN () 를 사용해서 특정 범위를 정해주면 된다.(LIST)
```
CREATE TABLE sales_2019 
PARTITION OF sales
FOR VALUES FROM ('2019-01-01') TO ('2020-01-01');
```
```
CREATE TABLE film_2019 
PARTITION OF film_partitioned 
FOR VALUES IN ('2019');
```

![Image](https://github.com/user-attachments/assets/6dbd19f3-e8e7-4086-898b-707c098e08e9)
- 마지막으로, 파티션에 사용한 열에 인덱스를 추가해주는 것이 좋다. 이는 검색속도를 최적화 할 수 있다.


- 수평 파티셔닝의 장점
    1) 인덱스를 최적화하여 메모리 내에서 더 자주 사용되는 인덱스가 유지될 가능성이 증가한다.
    2) 드물게 접근되는 파티션을 느린 저장 매체로 이동 가능하다.
    3) OLAP(분석) OLTP(트랜잭션) 모두에서 성능 향상이 가능하다.

- 수평 파티셔닝의 단점
    1) 기존 테이블을 파티셔닝하는 것은 번거롭고 데이터 복사 작업이 필요하다.
    2) 파티셔닝된 테이블에 PRIMARY KEY 같은 제약조건을 동일하게 설정할 수 **없는** 경우가 있다.


## 샤딩(Sharding)과의 관계

- 파티셔닝에서 더 나아가 샤딩을 통해 데이터를 여러 서버(머신)에 분산할 수 있다.

![Image](https://github.com/user-attachments/assets/f38bce55-2deb-47b4-ac55-2881ad819540)

- 샤딩(Sharding)은 **수평 파티셔닝을 확장** 하여 데이터를 여러 서버/노드에 분산하는 것을 말한다.
- 각 서버는 특정 파티션(샤드)에 대해 계산을 수행한다.
- MPP(Massively Parallel Processing) 데이터베이스에서 각 노드가 특정 샤드에 대해 병렬 계산을 수행한다.


<hr>

## 데이터 통합(Data integration)

- 데이터 통합은 다양한 소스, 포맷, 기술에서 데이터를 결합하여 사용자에게 **통합된 뷰** 를 제공하는 과정이다.
- 데이터가 여러 데이터베이스, 시스템, 포맷에 분산되어 있을 때, 이를 효율적으로 결합하여 활용한다.


- (ex) 고객 360도 뷰 : 모든 부서의 고객 데이터를 한 곳에 통합한다.
- (ex) 기업 인수 : 인수한 회사의 데이터베이스를 통합한다.
- (ex) 레거시 시스템 : 기존의 오래된 시스템과 새로운 시스템의 데이터를 통합한다.
    
## 통합 데이터 모델
- 통합 데이터 모델은 다양한 용도로 사용 가능하다.
    - 대시보드 : (ex) 일일 판매 그래프
    - 데이터 제품 : (ex) 추천 시스템

## 데이터 소스와 포맷
- 데이터 소스
    - PostgreSQL, MongoDB, CSV 등 다양한 포맷으로 저장이 가능하다.
- 통합 데이터 모델 포맷
    - AWS의 RedShift 와 같은 데이터 웨어하우스 서비스를 활용한다.

## 데이터 업데이트 주기
- (ex) 일일 업데이트 : 판매 데이터처럼 실시간이 필요 없는 경우
- (ex) 실시간 업데이트 : 항공 교통처럼 즉각적인 데이터 반영이 필요한 경우
- 데이터 소스별로 다른 업데이트 주기를 가질 수 있다.

![Image](https://github.com/user-attachments/assets/5374a2fa-9f40-4360-95af-b285df7feb2c)

## 데이터 변환
- 데이터 변환의 필요성
    - 서로 다른 포맷의 데이터를 통합 데이터 모델에 맞게 변환해야 한다.
- 변환 방법
    1) 수작업 코드 
        - 각 데이터 소스마다 변환 코드를 작성하고 유지보수를 한다.
        - ![Image](https://github.com/user-attachments/assets/f4944305-a075-483b-86e4-b99fd5bbb093)

    2) ETL 도구 사용
        - Apache Airflow, Scriptella 와 같은 도구로 효율적 처리한다.
        - ![Image](https://github.com/user-attachments/assets/add0cc48-7eed-4f70-8787-3250b48cb8df)

## 데이터 통합 도구 선택 기준

- 1)Flexiable(유연성,자동화)
    - 모든 데이터 소스와 연결 가능해야 한다.
- 2)Reliable(신뢰성)
    - 장기적으로 유지보수가 가능해야 한다.
- 3)Scalable(확장성)
    - 데이터 양과 소스가 증가해도 대응 가능해야 한다.
 

## 테스트 및 보안

- 1) 테스트 및 경고 시스템
    - 데이터 변환 중 문제가 발생하면 경고를 통해 즉시 알려줘야 한다.
    - (ex) 변환 후 총 판매 데이터가 동일한지 확인한다.

- 2) 보안
    - 원래 데이터가 제한된 접근 권한을 가지고 있었다면, 통합 모델에서도 동일하게 유지해야 한다.
    - (ex) 신용카드 번호를 익명화(마스킹)하여 분석가는 앞 4자리만 볼 수 있도록 설정되어야 한다.


## 데이터 거버넌스
- 데이터 계보(lineage)
    - 데이터가 어디에서 왔고, 어디에서 사용되었는지를 추적한다.
    - 효과적인 감사와 규정 준수를 위해 필수적이다.

### 즉, 데이터를 효율적으로 통합하기 위해서는 **변환, 보안, 데이터 거버넌스** 를 철저하게 관리해야 한다.


## DBMS(DataBase Management System)
- 데이터베이스를 생성하고 관리하기 위한 시스템 소프트웨어이다.
- 세 가지 주요 기능
    1) 데이터 : 데이터를 저장하고 관리한다.
    2) 데이터베이스 스키마 : 데이터베이스의 논리적 구조를 정의한다.
    3) 데이터베이스 엔진 : 데이터를 접근, 잠금, 수정할 수 있도록 지원한다.
    
- ![Image](https://github.com/user-attachments/assets/b7b0f1ff-4f06-41f4-aadd-0280f4d80f3b)

사용자나 애플리케이션 프로그램과 데이터베이스 사이의 **인터페이스 역할** 을 한다.

## DBMS 유형

1) SQL DBMS(Relational DBMS)
    - 관계형 데이터 모델에 기반한다.
    - 구조화된 데이터와 고정된 스키마에 적합하다.
    - 데이터 일관성과 정확성이 중요할 때 적합하다.(ex. 회계 시스템)
    - (ex) SQL Server,PostgreSQL,Oracle SQL

2) NoSQL DBMS(Non-relational DBMS)
    - 비관계형 데이터베이스로, 구조화되지 않은 데이터와 유연성이 요구되는 상황에 적합하다.
    - 데이터가 테이블형식에 국한되지 않는다.
    - 빠르게 변화하거나 명확한 스키마 정의가 없는 데이터에 적합하다.
    - (ex) Key-value store,Document store,Columnar,GraphDB

    - NoSQL DBMS 유형
        1) Key-value Store
       
            ![Image](https://github.com/user-attachments/assets/868f9b72-61d8-4ff6-a00e-9c1031bbbd7f)
            - **키와 값** 의 조합으로 데이터를 저장하는 구조이다.(값은 어떠한 유형도 가능하다.)
            - **세션 정보 관리** 혹은 **쇼핑 카트 데이터** 등이 이에 해당한다.
            - (ex) Redis
        2) Document Store
            
            ![Image](https://github.com/user-attachments/assets/9340930c-accd-4f68-a5a7-3981f74d7a40)
            - **키와 문서 (구조화된 데이터)** 의 조합이다.
            - **콘텐츠 관리 애플리케이션(블로그,비디오 플랫폼)** 등이 이에 해당한다.
            - (ex) MongoDB
        3) Columnar Database
            
            ![Image](https://github.com/user-attachments/assets/0431ecfd-d11f-4a5e-bad3-a1d9ed3c9625)
            - **열을 별도의 파일로 저장** 하여 확장성과 속도에 최적화된 구조이다.
            - **빅데이터 분석** 등이 이에 해당한다.
            - (ex) Cassandra
        4) GraphDB
        
            ![Image](https://github.com/user-attachments/assets/1a392c19-5097-4c2a-a661-316b2f7aa854)
            - **데이터 간의 관계를 그래프로 표현** 한 구조이다.
            - **소셜 네트워크** 나 **추천시스템** 이 이에 해당한다.
            - (ex) Neo4j


## SQL DBMS vs NoSQL DBMS
- SQL DBMS
    - 고정된 구조, 데이터의 일관성이 필요한 경우에 적합하다.
    - 데이터가 자주 변하지 않고, 예측 가능한 구조를 가진 애플리케이션에 적합하다.

- NoSQL DBMS
    - 데이터가 자주 변경되고 빠르게 증가하는 경우에 적합하다.
    - 빅데이터 분석이나 복잡한 데이터구조를 다룰 때 유리하다.

비즈니스 요구사항에 따라 적합한 DBMS 를 선택해야 한다.
